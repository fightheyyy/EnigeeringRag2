"""
MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡
ç”¨äºæŸ¥è¯¢å›½å®¶æ ‡å‡†ä¿¡æ¯å’Œæ–‡ä»¶å­˜æ”¾åœ°å€
"""

import pymysql
import logging
from typing import List, Dict, Optional, Any
import re
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class StandardInfo:
    """æ ‡å‡†ä¿¡æ¯æ•°æ®ç±»"""
    id: int
    standard_number: str
    standard_name: str
    file_url: str
    status: str
    publish_date: Optional[str] = None
    implement_date: Optional[str] = None
    document_id: Optional[str] = None

@dataclass
class RegulationInfo:
    """æ³•è§„ä¿¡æ¯æ•°æ®ç±»"""
    id: int
    legal_name: str
    legal_url: str

class MySQLStandardsService:
    """MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡"""
    
    def __init__(self, host: str, port: str, user: str, password: str, database: str):
        """
        åˆå§‹åŒ–MySQLè¿æ¥æœåŠ¡
        
        Args:
            host: æ•°æ®åº“ä¸»æœºåœ°å€
            port: ç«¯å£å·
            user: ç”¨æˆ·å
            password: å¯†ç 
            database: æ•°æ®åº“å
        """
        self.host = host
        self.port = int(port)
        self.user = user
        self.password = password
        self.database = database
        self.connection = None
        
        # æµ‹è¯•è¿æ¥
        self._test_connection()
        
    def _test_connection(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        try:
            connection = pymysql.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                database=self.database,
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            connection.close()
            logger.info(f"âœ… MySQLæ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ: {self.host}:{self.port}/{self.database}")
        except Exception as e:
            logger.error(f"âŒ MySQLæ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = pymysql.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                database=self.database,
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor,
                autocommit=True
            )
            return connection
        except Exception as e:
            logger.error(f"âŒ è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def search_standards_by_name(self, query: str, limit: int = 10) -> List[StandardInfo]:
        """
        æ ¹æ®æ ‡å‡†åç§°æœç´¢æ ‡å‡†ä¿¡æ¯
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æ ‡å‡†ä¿¡æ¯åˆ—è¡¨
        """
        connection = None
        try:
            connection = self._get_connection()
            with connection.cursor() as cursor:
                # ä½¿ç”¨LIKEè¿›è¡Œæ¨¡ç³Šæœç´¢ï¼ˆæœç´¢æ ‡å‡†åç§°å’Œæ ‡å‡†ç¼–å·ï¼‰
                sql = """
                SELECT id, standard_number, standard_name, status, 
                       publish_date, implement_date, file_url, document_id
                FROM standards 
                WHERE standard_name LIKE %s OR standard_number LIKE %s
                ORDER BY 
                    CASE WHEN standard_name = %s THEN 1 
                         WHEN standard_number = %s THEN 2 
                         ELSE 3 END,
                    CHAR_LENGTH(standard_name)
                LIMIT %s
                """
                
                like_query = f"%{query}%"
                cursor.execute(sql, (like_query, like_query, query, query, limit))
                results = cursor.fetchall()
                
                standards = []
                for row in results:
                    standard = StandardInfo(
                        id=row['id'],
                        standard_number=row['standard_number'],
                        standard_name=row['standard_name'],
                        file_url=row['file_url'],
                        status=row['status'],
                        publish_date=str(row['publish_date']) if row['publish_date'] else None,
                        implement_date=str(row['implement_date']) if row['implement_date'] else None,
                        document_id=row.get('document_id')
                    )
                    standards.append(standard)
                
                logger.info(f"ğŸ” æœç´¢æ ‡å‡† '{query}': æ‰¾åˆ° {len(standards)} ä¸ªç»“æœ")
                return standards
                
        except Exception as e:
            logger.error(f"âŒ æœç´¢æ ‡å‡†å¤±è´¥: {e}")
            return []
        finally:
            if connection:
                connection.close()
    
    def search_standards_by_keywords(self, keywords: List[str], limit: int = 5) -> List[StandardInfo]:
        """
        æ ¹æ®å…³é”®è¯åˆ—è¡¨æœç´¢æ ‡å‡†
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æ ‡å‡†ä¿¡æ¯åˆ—è¡¨
        """
        if not keywords:
            return []
        
        all_standards = []
        for keyword in keywords:
            standards = self.search_standards_by_name(keyword, limit)
            all_standards.extend(standards)
        
        # å»é‡ï¼ˆæ ¹æ®IDï¼‰
        seen_ids = set()
        unique_standards = []
        for standard in all_standards:
            if standard.id not in seen_ids:
                seen_ids.add(standard.id)
                unique_standards.append(standard)
        
        return unique_standards[:limit]
    
    def extract_standard_references(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–æ ‡å‡†å¼•ç”¨
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ ‡å‡†å¼•ç”¨åˆ—è¡¨
        """
        # å¸¸è§çš„æ ‡å‡†æ ¼å¼æ¨¡å¼
        patterns = [
            r'GB[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # GB 50010-2010, GB+8076-2008
            r'JGJ[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # JGJ 55-2011, JGJ+130-2011
            r'GB/T[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # GB/T 50152-2012
            r'JGJ/T[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # JGJ/T 385-2015
            r'CJJ[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # CJJ 1-2008
            r'DBJ[\s\+]*\d+(?:\.\d+)?(?:[-\+]\d+)?',  # DBJ 15-31-2016
        ]
        
        references = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            references.extend(matches)
        
        # å»é‡å¹¶æ¸…ç†
        unique_refs = []
        for ref in references:
            # æ¸…ç†æ ¼å¼ï¼šå°†+å·æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œç»Ÿä¸€æ ¼å¼
            clean_ref = re.sub(r'\+', ' ', ref.strip())
            clean_ref = re.sub(r'\s+', ' ', clean_ref)
            if clean_ref and clean_ref not in unique_refs:
                unique_refs.append(clean_ref)
        
        return unique_refs
    
    def find_standards_for_content(self, content: str, metadata: Dict[str, Any] = None) -> List[StandardInfo]:
        """
        ä¸ºç»™å®šå†…å®¹æŸ¥æ‰¾ç›¸å…³æ ‡å‡†
        
        Args:
            content: æ–‡æ¡£å†…å®¹
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            
        Returns:
            ç›¸å…³æ ‡å‡†ä¿¡æ¯åˆ—è¡¨
        """
        # 1. ä»å†…å®¹ä¸­æå–æ ‡å‡†å¼•ç”¨
        references = self.extract_standard_references(content)
        
        # 2. ä»å…ƒæ•°æ®ä¸­è·å–æ¥æºæ–‡ä»¶ä¿¡æ¯
        source_keywords = []
        if metadata:
            source_file = metadata.get('source_file', '')
            if source_file:
                # ä»æ–‡ä»¶åä¸­æå–å…³é”®è¯
                filename_refs = self.extract_standard_references(source_file)
                references.extend(filename_refs)
                
                # æå–å…¶ä»–å…³é”®è¯
                if 'å¤–åŠ å‰‚' in source_file:
                    source_keywords.append('å¤–åŠ å‰‚')
                if 'æ··å‡åœŸ' in source_file:
                    source_keywords.append('æ··å‡åœŸ')
        
        # 3. æœç´¢ç›¸å…³æ ‡å‡†
        all_standards = []
        
        # æœç´¢ç›´æ¥å¼•ç”¨çš„æ ‡å‡†
        for ref in references:
            standards = self.search_standards_by_name(ref, 3)
            all_standards.extend(standards)
        
        # æœç´¢å…³é”®è¯ç›¸å…³çš„æ ‡å‡†
        if source_keywords:
            keyword_standards = self.search_standards_by_keywords(source_keywords, 2)
            all_standards.extend(keyword_standards)
        
        # å»é‡
        seen_ids = set()
        unique_standards = []
        for standard in all_standards:
            if standard.id not in seen_ids:
                seen_ids.add(standard.id)
                unique_standards.append(standard)
        
        return unique_standards[:5]  # é™åˆ¶è¿”å›5ä¸ªæœ€ç›¸å…³çš„æ ‡å‡†
    
    def get_standard_by_id(self, standard_id: int) -> Optional[StandardInfo]:
        """
        æ ¹æ®IDè·å–æ ‡å‡†ä¿¡æ¯
        
        Args:
            standard_id: æ ‡å‡†ID
            
        Returns:
            æ ‡å‡†ä¿¡æ¯æˆ–None
        """
        connection = None
        try:
            connection = self._get_connection()
            with connection.cursor() as cursor:
                sql = """SELECT id, standard_number, standard_name, status, 
                        publish_date, implement_date, file_url, document_id 
                        FROM standards WHERE id = %s"""
                cursor.execute(sql, (standard_id,))
                row = cursor.fetchone()
                
                if row:
                    return StandardInfo(
                        id=row['id'],
                        standard_number=row['standard_number'],
                        standard_name=row['standard_name'],
                        file_url=row['file_url'],
                        status=row['status'],
                        publish_date=str(row['publish_date']) if row['publish_date'] else None,
                        implement_date=str(row['implement_date']) if row['implement_date'] else None,
                        document_id=row.get('document_id')
                    )
                return None
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ ‡å‡†ä¿¡æ¯å¤±è´¥: {e}")
            return None
        finally:
            if connection:
                connection.close()
    
    def get_all_standards_count(self) -> int:
        """è·å–æ ‡å‡†æ€»æ•°"""
        connection = None
        try:
            connection = self._get_connection()
            with connection.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) as count FROM standards")
                result = cursor.fetchone()
                return result['count'] if result else 0
        except Exception as e:
            logger.error(f"âŒ è·å–æ ‡å‡†æ€»æ•°å¤±è´¥: {e}")
            return 0
        finally:
            if connection:
                connection.close()
    
    def get_standards_summary(self) -> Dict[str, Any]:
        """è·å–æ ‡å‡†æ•°æ®åº“æ‘˜è¦ä¿¡æ¯"""
        try:
            total_count = self.get_all_standards_count()
            
            # è·å–ä¸€äº›ç¤ºä¾‹æ ‡å‡†
            sample_standards = self.search_standards_by_name("GB", 5)
            
            return {
                "total_count": total_count,
                "database_name": self.database,
                "host": self.host,
                "sample_standards": [
                    {"id": s.id, "standard_number": s.standard_number, 
                     "standard_name": s.standard_name, "file_url": s.file_url} 
                    for s in sample_standards
                ]
            }
        except Exception as e:
            logger.error(f"âŒ è·å–æ•°æ®åº“æ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def search_regulations_by_name(self, query: str, limit: int = 10) -> List[RegulationInfo]:
        """
        æ ¹æ®æ³•è§„åç§°æœç´¢æ³•è§„ä¿¡æ¯
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æ³•è§„ä¿¡æ¯åˆ—è¡¨
        """
        connection = None
        try:
            connection = self._get_connection()
            with connection.cursor() as cursor:
                # ä½¿ç”¨LIKEè¿›è¡Œæ¨¡ç³Šæœç´¢
                sql = """
                SELECT id, legal_name, legal_url
                FROM regulations 
                WHERE legal_name LIKE %s
                ORDER BY 
                    CASE WHEN legal_name = %s THEN 1 
                         ELSE 2 END,
                    CHAR_LENGTH(legal_name)
                LIMIT %s
                """
                
                like_query = f"%{query}%"
                cursor.execute(sql, (like_query, query, limit))
                results = cursor.fetchall()
                
                regulations = []
                for row in results:
                    regulation = RegulationInfo(
                        id=row['id'],
                        legal_name=row['legal_name'],
                        legal_url=row['legal_url']
                    )
                    regulations.append(regulation)
                
                logger.info(f"ğŸ” æœç´¢æ³•è§„ '{query}': æ‰¾åˆ° {len(regulations)} ä¸ªç»“æœ")
                return regulations
                
        except Exception as e:
            logger.error(f"âŒ æœç´¢æ³•è§„å¤±è´¥: {e}")
            return []
        finally:
            if connection:
                connection.close()
    
    def find_regulation_by_content_keywords(self, content: str) -> List[RegulationInfo]:
        """
        æ ¹æ®å†…å®¹å…³é”®è¯æŸ¥æ‰¾ç›¸å…³æ³•è§„
        
        Args:
            content: å†…å®¹æ–‡æœ¬
            
        Returns:
            ç›¸å…³æ³•è§„ä¿¡æ¯åˆ—è¡¨
        """
        logger.info(f"ğŸ” æŸ¥æ‰¾æ³•è§„ï¼Œå†…å®¹: '{content}'")
        
        # ç›´æ¥æœç´¢å®Œæ•´çš„æ³•è§„åç§°
        all_regulations = []
        
        # å¦‚æœå†…å®¹å°±æ˜¯æ³•è§„åç§°ï¼Œç›´æ¥æœç´¢
        regulations = self.search_regulations_by_name(content, 3)
        if regulations:
            logger.info(f"âœ… ç›´æ¥åŒ¹é…åˆ°æ³•è§„: {[r.legal_name for r in regulations]}")
            all_regulations.extend(regulations)
        
        # æå–æ³•è§„å…³é”®è¯è¿›è¡Œæœç´¢
        keywords = []
        
        # å¸¸è§æ³•è§„å…³é”®è¯
        regulation_keywords = [
            'ä½å®…ä¸“é¡¹ç»´ä¿®èµ„é‡‘', 'å»ºç­‘å·¥ç¨‹æ–½å·¥', 'å»ºç­‘å·¥ç¨‹è´¨é‡', 'æˆ¿åœ°äº§ç»çºª', 
            'å•†å“æˆ¿é”€å”®', 'å®‰å…¨ç”Ÿäº§ç®¡ç†', 'åŸå¸‚æˆ¿å±‹ä¾¿å™¨', 'åŸå¸‚å…¬å•', 
            'ä¾¿å™¨æ°´ç®±', 'å…¬å•ç®¡ç†', 'æˆ¿å±‹ä¾¿å™¨', 'æ°´ç®±åº”ç”¨'
        ]
        
        # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«è¿™äº›å…³é”®è¯
        for keyword in regulation_keywords:
            if keyword in content:
                keywords.append(keyword)
        
        # å¦‚æœå†…å®¹åŒ…å«"åŠæ³•"ã€"è§„å®š"ç­‰æ³•è§„æ ‡è¯†è¯ï¼Œæå–ç›¸å…³è¯æ±‡
        if any(term in content for term in ['åŠæ³•', 'è§„å®š', 'æ¡ä¾‹', 'æ³•å¾‹', 'æ³•è§„']):
            # æå–å¯èƒ½çš„æ³•è§„åç§°ç‰‡æ®µ
            import re
            # æå–åŒ…å«æ³•è§„æ ‡è¯†è¯çš„çŸ­è¯­
            pattern = r'[\u4e00-\u9fff]+(?:åŠæ³•|è§„å®š|æ¡ä¾‹|æ³•å¾‹|æ³•è§„)'
            matches = re.findall(pattern, content)
            for match in matches:
                if len(match) > 4:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                    keywords.append(match)
        
        # å»é‡
        keywords = list(set(keywords))
        logger.info(f"ğŸ” æå–åˆ°æ³•è§„å…³é”®è¯: {keywords}")
        
        # æœç´¢æ³•è§„
        for keyword in keywords[:5]:  # æœ€å¤šæœç´¢5ä¸ªå…³é”®è¯
            regulations = self.search_regulations_by_name(keyword, 2)
            if regulations:
                logger.info(f"âœ… å…³é”®è¯ '{keyword}' åŒ¹é…åˆ°æ³•è§„: {[r.legal_name for r in regulations]}")
            all_regulations.extend(regulations)
        
        # å»é‡
        seen_ids = set()
        unique_regulations = []
        for regulation in all_regulations:
            if regulation.id not in seen_ids:
                seen_ids.add(regulation.id)
                unique_regulations.append(regulation)
        
        logger.info(f"ğŸ¯ æœ€ç»ˆæ‰¾åˆ° {len(unique_regulations)} ä¸ªæ³•è§„")
        return unique_regulations[:3]  # æœ€å¤šè¿”å›3ä¸ªç›¸å…³æ³•è§„

# åˆ›å»ºå…¨å±€å®ä¾‹
mysql_standards_service = None

def get_mysql_standards_service() -> MySQLStandardsService:
    """è·å–MySQLæ ‡å‡†æœåŠ¡å®ä¾‹"""
    global mysql_standards_service
    if mysql_standards_service is None:
        # ä½¿ç”¨æä¾›çš„æ•°æ®åº“é…ç½®
        mysql_standards_service = MySQLStandardsService(
            host="gz-cdb-e0aa423v.sql.tencentcdb.com",
            port="20236",
            user="root",
            password="Aa@114514",
            database="gauz_ai_messages"
        )
    return mysql_standards_service

if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    print("ğŸ§ª æµ‹è¯•MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡...")
    
    service = get_mysql_standards_service()
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½:")
    results = service.search_standards_by_name("GB", 3)
    for result in results:
        print(f"  - {result.standard_number}: {result.standard_name}")
        print(f"    URL: {result.file_url}")
        print(f"    çŠ¶æ€: {result.status}")
    
    # æµ‹è¯•æ ‡å‡†å¼•ç”¨æå–
    print("\nğŸ“ æµ‹è¯•æ ‡å‡†å¼•ç”¨æå–:")
    test_text = "æ ¹æ®GB 50010-2010å’ŒJGJ 55-2011è§„èŒƒè¦æ±‚..."
    refs = service.extract_standard_references(test_text)
    print(f"  æå–çš„æ ‡å‡†: {refs}")
    
    # è·å–æ‘˜è¦ä¿¡æ¯
    print("\nğŸ“Š æ•°æ®åº“æ‘˜è¦:")
    summary = service.get_standards_summary()
    print(f"  æ€»æ ‡å‡†æ•°: {summary.get('total_count', 0)}")
    print(f"  æ•°æ®åº“: {summary.get('database_name')}") 