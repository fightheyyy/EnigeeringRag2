from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from datetime import datetime
import uuid
import logging
import os
import re
from typing import List, Optional, Dict

from core.config import Config
from core.models import QuestionRequest, AnswerResponse, KnowledgeDocument, SystemStatus  
from services.bigmodel_knowledge_base import BigModelKnowledgeBase as KnowledgeBaseManager
from services.llm_service import LLMService, enhance_engineering_question
from services.mysql_standards_service import get_mysql_standards_service
from services.drawing_upload_service import get_drawing_service

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(
    title="å·¥ç¨‹ç›‘ç†æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    description="ä¸ºç°åœºç›‘ç†å·¥ç¨‹å¸ˆæä¾›è§„èŒƒå’Œå›¾çº¸æŸ¥è¯¢æœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory="static"), name="static")

# åˆå§‹åŒ–æœåŠ¡
config = Config()

# çŸ¥è¯†åº“é…ç½® - æ”¯æŒå¤šä¸ªä¸“é—¨çš„çŸ¥è¯†åº“
KNOWLEDGE_BASES = {
    "standards": "å›½å®¶æ ‡å‡†åº“",
    "engineering_knowledge_base": "åŸæœ‰å·¥ç¨‹çŸ¥è¯†åº“", 
    "regulations": "æ³•å¾‹æ³•è§„åº“",
    "drawings": "é¡¹ç›®å›¾çº¸åº“"      # é¢„ç•™
}

# é»˜è®¤ä½¿ç”¨standardsé›†åˆï¼ˆå›½å®¶æ ‡å‡†åº“ï¼‰
DEFAULT_COLLECTION = "standards"

# ä½¿ç”¨BigModelçŸ¥è¯†åº“ï¼ŒæŒ‡å®šstandardsé›†åˆ
kb_manager = KnowledgeBaseManager(
    api_key=config.bigmodel_api_key,
    collection_name=DEFAULT_COLLECTION
)
llm_service = LLMService()

# åˆå§‹åŒ–MySQLæ ‡å‡†æœåŠ¡
try:
    standards_service = get_mysql_standards_service()
    logger.info("âœ… MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    standards_service = None

# åˆå§‹åŒ–å›¾çº¸ä¸Šä¼ æœåŠ¡
try:
    drawing_service = get_drawing_service()
    logger.info("âœ… å›¾çº¸ä¸Šä¼ æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ å›¾çº¸ä¸Šä¼ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    drawing_service = None

# å­˜å‚¨ä¼šè¯å†å²ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­åº”ä½¿ç”¨æ•°æ®åº“ï¼‰
session_history = {}

def extract_used_standards_from_answer(answer: str) -> List[str]:
    """ä»ç­”æ¡ˆä¸­æå–DeepSeekæ ‡æ³¨çš„ä½¿ç”¨æ ‡å‡†"""
    # æŸ¥æ‰¾[ä½¿ç”¨æ ‡å‡†: XXX]æ ¼å¼çš„æ ‡æ³¨
    pattern = r'\[ä½¿ç”¨æ ‡å‡†:\s*([^\]]+)\]'
    match = re.search(pattern, answer)
    
    if match:
        standards_text = match.group(1).strip()
        if standards_text.lower() == "æ— ":
            return []
        
        # åˆ†å‰²å¤šä¸ªæ ‡å‡†ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
        standards = [std.strip() for std in standards_text.split(',')]
        return [std for std in standards if std]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    
    return []

def analyze_answer_sources(answer: str, sources: List) -> Dict[str, List]:
    """
    åˆ†æç­”æ¡ˆä¸­å®é™…ä½¿ç”¨çš„æ¥æºç±»å‹
    
    Args:
        answer: å¤§æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ
        sources: æ£€ç´¢åˆ°çš„æ‰€æœ‰æ¥æº
        
    Returns:
        DictåŒ…å«ä¸åŒç±»å‹çš„æ¥æºä¿¡æ¯
    """
    used_sources = {
        'standards': [],  # æ ‡å‡†æ¥æº
        'regulations': [],  # æ³•è§„æ¥æº  
        'drawings': [],  # å›¾çº¸æ¥æº
        'source_files': []  # æ‰€æœ‰æ¥æºæ–‡ä»¶å
    }
    
    # ä»ç­”æ¡ˆçš„å‚è€ƒæ¥æºéƒ¨åˆ†æå–å®é™…ä½¿ç”¨çš„æ¥æº
    import re
    
    # æ–¹æ³•1: æŸ¥æ‰¾ğŸ“š å‚è€ƒæ¥æºéƒ¨åˆ†
    source_pattern = r'ğŸ“š å‚è€ƒæ¥æºï¼š\s*(.*?)(?=ğŸ’­|$)'
    source_match = re.search(source_pattern, answer, re.DOTALL)
    
    if source_match:
        source_text = source_match.group(1)
        
        # æå–æ¥æºæ–‡ä»¶åï¼ˆæ ¼å¼ï¼š1. æ–‡ä»¶å - å—X (ç›¸å…³åº¦: XX.X%)ï¼‰
        # ä¿®æ”¹æ­£åˆ™è¡¨è¾¾å¼ä»¥æ›´å¥½åœ°åŒ¹é…æ–‡ä»¶å
        file_pattern = r'\d+\.\s*([^-\n]+?)(?:\s*-\s*å—|\s*\()'
        file_matches = re.findall(file_pattern, source_text)
        
        for file_name in file_matches:
            file_name = file_name.strip()
            used_sources['source_files'].append(file_name)
            _classify_source_type(file_name, used_sources)
    
    # æ–¹æ³•2: æŸ¥æ‰¾ç­”æ¡ˆä¸­çš„ï¼ˆæ¥æºï¼šå—Xï¼‰æ ¼å¼
    block_pattern = r'ï¼ˆæ¥æºï¼šå—(\d+)ï¼‰'
    block_matches = re.findall(block_pattern, answer)
    
    if block_matches and sources:
        logger.info(f"ğŸ” åœ¨ç­”æ¡ˆä¸­å‘ç°å—å¼•ç”¨: {block_matches}")
        for block_num in block_matches:
            try:
                block_index = int(block_num)
                # ä»sourcesåˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„æ¥æº
                if 0 <= block_index < len(sources):
                    source = sources[block_index]
                    file_name = source.file_name if hasattr(source, 'file_name') else str(source)
                    used_sources['source_files'].append(file_name)
                    _classify_source_type(file_name, used_sources)
                    logger.info(f"âœ… è¯†åˆ«åˆ°æ¥æº: å—{block_index} -> {file_name}")
            except (ValueError, IndexError):
                continue
    
    # æ–¹æ³•3: æŸ¥æ‰¾ç­”æ¡ˆä¸­çš„æ–‡æœ¬å¼•ç”¨ï¼ˆå¦‚"ä»¥ä¸Šä¿¡æ¯æ¥æºäºç»“æ„è®¾è®¡æ€»è¯´æ˜äºŒ"ï¼‰
    text_source_patterns = [
        r'ä»¥ä¸Šä¿¡æ¯æ¥æºäº([^ä¸­ã€‚ï¼Œ]+)',
        r'ä¿¡æ¯æ¥æºäº([^ä¸­ã€‚ï¼Œ]+)',
        r'æ¥æºäº([^ä¸­ã€‚ï¼Œ]+)',
        r'æ ¹æ®([^ä¸­ã€‚ï¼Œ]*è®¾è®¡è¯´æ˜[^ä¸­ã€‚ï¼Œ]*)',
        r'å‚è€ƒ([^ä¸­ã€‚ï¼Œ]*è®¾è®¡è¯´æ˜[^ä¸­ã€‚ï¼Œ]*)'
    ]
    
    for pattern in text_source_patterns:
        text_matches = re.findall(pattern, answer)
        for match in text_matches:
            source_name = match.strip()
            if len(source_name) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                used_sources['source_files'].append(source_name)
                _classify_source_type(source_name, used_sources)
                logger.info(f"âœ… è¯†åˆ«åˆ°æ–‡æœ¬æ¥æº: {source_name}")
    
    # ä¹Ÿä»[ä½¿ç”¨æ ‡å‡†: XXX]ä¸­æå–
    used_standards = extract_used_standards_from_answer(answer)
    if used_standards and "æ— " not in used_standards:
        for standard in used_standards:
            if any(indicator in standard for indicator in ['ä½å®…æ¥¼', 'è®¾è®¡è¯´æ˜', 'å›¾çº¸', 'å¤§æ ·']):
                used_sources['drawings'].append(standard)
            else:
                used_sources['standards'].append(standard)
    
    return used_sources

def _classify_source_type(file_name: str, used_sources: Dict[str, List]):
    """æ ¹æ®æ–‡ä»¶ååˆ†ç±»æ¥æºç±»å‹"""
    # å›¾çº¸è¯†åˆ«ï¼šåŒ…å«ä½å®…æ¥¼ã€è®¾è®¡è¯´æ˜ç­‰å…³é”®è¯
    drawing_keywords = ['ä½å®…æ¥¼', 'è®¾è®¡è¯´æ˜', 'å›¾çº¸', 'å¤§æ ·', 'è¯¦å›¾', 'æ–½å·¥å›¾', 'ç»“æ„', 'å»ºç­‘', 'ç»™æ’æ°´', 'ç”µæ°”', 'æš–é€š', 'æ¡©åŸº', 'åŸºç¡€', 'å¹³é¢å›¾', 'ç«‹é¢å›¾', 'å‰–é¢å›¾']
    if any(keyword in file_name for keyword in drawing_keywords):
        used_sources['drawings'].append(file_name)
    # æ ‡å‡†è¯†åˆ«ï¼šGBã€JGJç­‰å¼€å¤´æˆ–åŒ…å«.txt
    elif (any(file_name.startswith(prefix) for prefix in ['GB', 'JGJ', 'CJJ', 'JTG', 'JTS', 'CJ']) or 
          file_name.endswith('.txt')):
        used_sources['standards'].append(file_name)
    # æ³•è§„è¯†åˆ«ï¼šåŒ…å«ç®¡ç†åŠæ³•ã€æ¡ä¾‹ç­‰
    elif any(keyword in file_name for keyword in ['ç®¡ç†åŠæ³•', 'æ¡ä¾‹', 'æš‚è¡ŒåŠæ³•', 'è§„å®š', 'é€šçŸ¥', 'æ„è§']):
        used_sources['regulations'].append(file_name)

def optimize_reference_display(answer: str) -> str:
    """ä¼˜åŒ–å‚è€ƒä¾æ®æ˜¾ç¤ºï¼Œéšè—å€¼ä¸º"æ— "çš„ç±»åˆ«ï¼Œå¹¶ä½¿ç”¨Markdownæ ¼å¼"""
    import re
    
    # æŸ¥æ‰¾å‚è€ƒä¾æ®éƒ¨åˆ†
    reference_pattern = r'ğŸ“š\s*\*\*å‚è€ƒä¾æ®\*\*\s*(.*?)(?=\n\n|$)'
    reference_match = re.search(reference_pattern, answer, re.DOTALL)
    
    if not reference_match:
        return answer
    
    reference_content = reference_match.group(1).strip()
    
    # æå–å„ä¸ªç±»åˆ«
    categories = {
        'ä½¿ç”¨æ ‡å‡†': r'\[ä½¿ç”¨æ ‡å‡†:\s*([^\]]+)\]',
        'å¼•ç”¨æ³•è§„': r'\[å¼•ç”¨æ³•è§„:\s*([^\]]+)\]', 
        'å¼•ç”¨å›¾çº¸': r'\[å¼•ç”¨å›¾çº¸:\s*([^\]]+)\]',
        'å‚è€ƒæ–‡æ¡£': r'\[å‚è€ƒæ–‡æ¡£:\s*([^\]]+)\]'
    }
    
    # æ„å»ºæ–°çš„å‚è€ƒä¾æ®éƒ¨åˆ†
    new_reference_lines = ["## ğŸ“š å‚è€ƒä¾æ®"]
    
    for category_name, pattern in categories.items():
        match = re.search(pattern, reference_content)
        if match:
            value = match.group(1).strip()
            if value and value != "æ— ":
                new_reference_lines.append(f"**{category_name}**: {value}")
    
    # å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰æ•ˆçš„å‚è€ƒä¾æ®ï¼Œä¿æŒåŸæ ·
    if len(new_reference_lines) == 1:
        return answer
    
    # æ›¿æ¢åŸæ¥çš„å‚è€ƒä¾æ®éƒ¨åˆ†
    new_reference_section = "\n".join(new_reference_lines)
    
    # æ›¿æ¢ç­”æ¡ˆä¸­çš„å‚è€ƒä¾æ®éƒ¨åˆ†
    new_answer = re.sub(
        r'ğŸ“š\s*\*\*å‚è€ƒä¾æ®\*\*.*?(?=\n\n|$)', 
        new_reference_section, 
        answer, 
        flags=re.DOTALL
    )
    
    return new_answer

def smart_filter_standards(answer: str, standards: List) -> List:
    """æ™ºèƒ½è¿‡æ»¤æ ‡å‡†ï¼šåŸºäºç­”æ¡ˆå†…å®¹è¿‡æ»¤å‡ºçœŸæ­£ç›¸å…³çš„æ ‡å‡†"""
    if not standards:
        return []
    
    # ä¸ç›¸å…³çš„æ ‡å‡†å…³é”®è¯
    irrelevant_keywords = [
        "æ°´æ•ˆé™å®šå€¼", "æ°´æ•ˆç­‰çº§", "åä¾¿å™¨", "è¹²ä¾¿å™¨", "å°ä¾¿å™¨", 
        "ä¾¿å™¨å†²æ´—é˜€", "èŠ‚æ°´", "ç”¨æ°´é‡", "å†²æ´—åŠŸèƒ½"
    ]
    
    # ç›¸å…³çš„æ ‡å‡†å…³é”®è¯
    relevant_keywords = [
        "åº”æ€¥é¿éš¾åœºæ‰€", "åœ°éœ‡åº”æ€¥", "åº”æ€¥å•æ‰€", "é¿éš¾åœºæ‰€", 
        "åœºå€åŠé…å¥—è®¾æ–½", "21734"
    ]
    
    filtered = []
    for standard in standards:
        standard_name = standard.standard_name.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç›¸å…³å…³é”®è¯
        is_irrelevant = any(keyword in standard_name for keyword in irrelevant_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
        is_relevant = any(keyword in standard_name.lower() for keyword in relevant_keywords)
        
        # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦ç›´æ¥æåŠè¯¥æ ‡å‡†
        answer_lower = answer.lower()
        standard_mentioned = (
            standard.standard_number.lower() in answer_lower or
            standard.standard_number.replace("-", "").replace(" ", "").lower() in answer_lower.replace("-", "").replace(" ", "")
        )
        
        # å†³ç­–é€»è¾‘ï¼š
        # 1. å¦‚æœåœ¨ç­”æ¡ˆä¸­è¢«æ˜ç¡®æåŠï¼Œåˆ™åŒ…å«
        # 2. å¦‚æœåŒ…å«ç›¸å…³å…³é”®è¯ä¸”ä¸åŒ…å«ä¸ç›¸å…³å…³é”®è¯ï¼Œåˆ™åŒ…å«
        # 3. å¦‚æœåŒ…å«ä¸ç›¸å…³å…³é”®è¯ï¼Œåˆ™æ’é™¤
        if standard_mentioned or (is_relevant and not is_irrelevant):
            filtered.append(standard)
        elif is_irrelevant:
            # æ˜ç¡®æ’é™¤ä¸ç›¸å…³çš„æ ‡å‡†
            logger.info(f"è¿‡æ»¤æ‰ä¸ç›¸å…³æ ‡å‡†: {standard.standard_number} - {standard.standard_name}")
            continue
    
    # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ ‡å‡†ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€ç›¸å…³çš„ï¼‰
    if not filtered and standards:
        filtered = [standards[0]]
    
    # æœ€å¤šè¿”å›2ä¸ªæ ‡å‡†ä»¥é¿å…ä¿¡æ¯è¿‡è½½
    return filtered[:2]

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    logger.info("å·¥ç¨‹ç›‘ç†æ™ºèƒ½é—®ç­”ç³»ç»Ÿå¯åŠ¨ä¸­...")
    
    # æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“ä¿¡æ¯
    try:
        info = kb_manager.get_collection_info()
        logger.info(f"ğŸ“š å½“å‰çŸ¥è¯†åº“: {KNOWLEDGE_BASES[DEFAULT_COLLECTION]} ({DEFAULT_COLLECTION})")
        logger.info(f"ğŸ“Š æ–‡æ¡£æ•°é‡: {info.get('count', 0)} ä¸ª")
        logger.info(f"ğŸ¤– å‘é‡æ¨¡å‹: {info.get('embedding_model', 'unknown')}")
        logger.info(f"ğŸ“ å‘é‡ç»´åº¦: {info.get('embedding_dimension', 0)}")
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºMySQLæ ‡å‡†åº“çŠ¶æ€
    if standards_service:
        logger.info("âœ… MySQLæ ‡å‡†æ•°æ®åº“é›†æˆå·²å¯ç”¨")
    else:
        logger.warning("âš ï¸ MySQLæ ‡å‡†æ•°æ®åº“é›†æˆæœªå¯ç”¨")
    
    logger.info("ç³»ç»Ÿå¯åŠ¨å®Œæˆ")

@app.get("/", response_class=FileResponse)
async def get_homepage():
    """è¿”å›ä¸»é¡µ"""
    return FileResponse("static/index.html")

@app.get("/admin", response_class=FileResponse)
async def get_admin_page():
    """è¿”å›ç®¡ç†é¡µé¢"""
    return FileResponse("static/admin.html")

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """å¤„ç†ç”¨æˆ·é—®é¢˜"""
    try:
        logger.info(f"æ”¶åˆ°é—®é¢˜: {request.question}")
        
        # åˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“ç®¡ç†å™¨
        standards_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name="standards"
        )
        regulations_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name="regulations"
        )
        
        # æ­¥éª¤1: ç›´æ¥ä½¿ç”¨ç”¨æˆ·é—®é¢˜æ£€ç´¢çŸ¥è¯†åº“ï¼ˆä¸æ·»åŠ é¢å¤–å†…å®¹ï¼‰
        user_question = request.question
        
        # æ­¥éª¤2: æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“
        all_results = []
        seen_content = set()  # é¿å…é‡å¤å†…å®¹
        
        logger.info("ğŸ” å¼€å§‹æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“...")
        
        # æœç´¢å›½å®¶æ ‡å‡†åº“
        logger.info(f"ğŸ“Š æœç´¢standardsåº“: {user_question}")
        standards_result = standards_kb_manager.search(user_question, n_results=config.MAX_RETRIEVAL_RESULTS)
        
        if standards_result and "results" in standards_result:
            for result in standards_result["results"]:
                content_hash = hash(result['content'][:100])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    result['source_type'] = 'standards'
                    all_results.append(result)
        
        # æœç´¢æ³•è§„åº“
        logger.info(f"ğŸ›ï¸ æœç´¢regulationsåº“: {user_question}")
        regulations_result = regulations_kb_manager.search(user_question, n_results=config.MAX_RETRIEVAL_RESULTS)
        
        if regulations_result and "results" in regulations_result:
            for result in regulations_result["results"]:
                content_hash = hash(result['content'][:100])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    result['source_type'] = 'regulations'
                    all_results.append(result)
        
        # æœç´¢å›¾çº¸çŸ¥è¯†åº“
        if drawing_service and drawing_service.drawings_kb:
            try:
                logger.info(f"ğŸ“‹ æœç´¢drawingsåº“: {user_question}")
                drawings_result = drawing_service.drawings_kb.search(user_question, n_results=config.MAX_RETRIEVAL_RESULTS)
                
                if drawings_result and "results" in drawings_result:
                    for result in drawings_result["results"]:
                        content_hash = hash(result['content'][:100])
                        if content_hash not in seen_content:
                            seen_content.add(content_hash)
                            result['source_type'] = 'drawings'
                            all_results.append(result)
            except Exception as e:
                logger.warning(f"å›¾çº¸çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶å–å‰Nä¸ªç»“æœ
        all_results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
        final_results = all_results[:config.MAX_RETRIEVAL_RESULTS * 2]
        
        # åŒ…è£…ä¸ºæ ‡å‡†æ ¼å¼
        sources_result = {"results": final_results}
        
        # å¤„ç†æœç´¢ç»“æœå¹¶åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        sources = []
        if sources_result and "results" in sources_result:
            for result in sources_result["results"]:
                similarity = result.get('similarity', 0)
                if similarity >= config.SIMILARITY_THRESHOLD:
                    # åˆ›å»ºå…¼å®¹DocumentSourceæ¨¡å‹çš„å¯¹è±¡
                    from core.models import DocumentSource
                    
                    metadata = result.get('metadata', {})
                    source_obj = DocumentSource(
                        title=metadata.get('standard_number', 'æœªçŸ¥æ ‡å‡†'),
                        content=result['content'],
                        source=metadata.get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                        similarity=similarity,
                        metadata=metadata,
                        file_name=metadata.get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                        regulation_code=metadata.get('standard_number', ''),
                        section=f"å—{metadata.get('chunk_index', 0)}",
                        similarity_score=similarity
                    )
                    sources.append(source_obj)
        
        if not sources:
            logger.warning(f"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼ˆé˜ˆå€¼: {config.SIMILARITY_THRESHOLD}ï¼‰ï¼Œä½¿ç”¨æ¨¡å‹é€šç”¨çŸ¥è¯†å›ç­”")
            # å½“çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³å†…å®¹æ—¶ï¼Œè®©å¤§æ¨¡å‹åŸºäºè‡ªèº«çŸ¥è¯†ç”Ÿæˆç­”æ¡ˆ
            return llm_service.generate_answer_without_context(request.question)
        
        # è·å–ä¼šè¯å†å²
        session_id = request.session_id or "default"
        history = session_history.get(session_id, [])
        
        # æ­¥éª¤3: å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        response = llm_service.generate_answer(
            question=request.question,
            sources=sources,
            context_history=history
        )
        
                # æ­¥éª¤4: æ ¹æ®ç­”æ¡ˆä¸­çš„ç»“æ„åŒ–å‚è€ƒä¾æ®æ£€ç´¢URL
        related_standards = []
        related_regulations = []
        related_drawings = []
        
        if standards_service:
            try:
                logger.info("ğŸ” æ ¹æ®ç»“æ„åŒ–å‚è€ƒä¾æ®æ£€ç´¢ç›¸å…³URL...")
                answer_text = response.answer
                
                # æå–ç»“æ„åŒ–å‚è€ƒä¾æ®
                import re
                reference_section_pattern = r'ğŸ“š\s*\*\*å‚è€ƒä¾æ®\*\*\s*(.*?)(?:\n\n|$)'
                reference_match = re.search(reference_section_pattern, answer_text, re.DOTALL)
                
                if reference_match:
                    reference_content = reference_match.group(1).strip()
                    logger.info(f"ğŸ“š æ‰¾åˆ°å‚è€ƒä¾æ®éƒ¨åˆ†: {reference_content}")
                    
                    # 4.1 æå–å¹¶æ£€ç´¢æ ‡å‡†URL
                    standard_pattern = r'\[ä½¿ç”¨æ ‡å‡†:\s*([^\]]+)\]'
                    standard_match = re.search(standard_pattern, reference_content)
                    if standard_match:
                        standards_text = standard_match.group(1).strip()
                        if standards_text and standards_text != "æ— ":
                            standard_refs = [s.strip() for s in standards_text.split(',') if s.strip()]
                            logger.info(f"ğŸ“Š æå–åˆ°æ ‡å‡†å¼•ç”¨: {standard_refs}")
                            for ref in standard_refs:
                                standards = standards_service.search_standards_by_name(ref, 2)
                                related_standards.extend(standards)
                    
                    # 4.2 æå–å¹¶æ£€ç´¢æ³•è§„URL
                    regulation_pattern = r'\[å¼•ç”¨æ³•è§„:\s*([^\]]+)\]'
                    regulation_match = re.search(regulation_pattern, reference_content)
                    if regulation_match:
                        regulations_text = regulation_match.group(1).strip()
                        if regulations_text and regulations_text != "æ— ":
                            regulation_refs = [r.strip() for r in regulations_text.split(',') if r.strip()]
                            logger.info(f"ğŸ›ï¸ æå–åˆ°æ³•è§„å¼•ç”¨: {regulation_refs}")
                            # åŸºäºæ³•è§„åç§°æ£€ç´¢
                            regulations = standards_service.find_regulation_by_content_keywords(' '.join(regulation_refs))
                            related_regulations.extend(regulations)
                    
                    # 4.3 æå–å¹¶æ£€ç´¢å›¾çº¸URL
                    drawing_pattern = r'\[å¼•ç”¨å›¾çº¸:\s*([^\]]+)\]'
                    drawing_match = re.search(drawing_pattern, reference_content)
                    if drawing_match:
                        drawings_text = drawing_match.group(1).strip()
                        if drawings_text and drawings_text != "æ— ":
                            drawing_refs = [d.strip() for d in drawings_text.split(',') if d.strip()]
                            logger.info(f"ğŸ“ æå–åˆ°å›¾çº¸å¼•ç”¨: {drawing_refs}")
                            
                            if drawing_service:
                                drawings = drawing_service.get_drawings_list(limit=50)
                                for drawing_ref in drawing_refs:
                                    for drawing_info in drawings:
                                        drawing_db_name = drawing_info.get('drawing_name', '')
                                        original_filename = drawing_info.get('original_filename', '')
                                        
                                        # ç²¾ç¡®åŒ¹é…æˆ–åŒ…å«åŒ¹é…
                                        if (drawing_ref in drawing_db_name or 
                                            drawing_db_name in drawing_ref or
                                            drawing_ref in original_filename):
                                            related_drawings.append(drawing_info)
                                            logger.info(f"âœ… åŒ¹é…åˆ°å›¾çº¸: {drawing_db_name}")
                                            break
                    
                    # 4.4 æå–å¹¶æ£€ç´¢å‚è€ƒæ–‡æ¡£URLï¼ˆä¹Ÿä½œä¸ºå›¾çº¸æ£€ç´¢ï¼‰
                    document_pattern = r'\[å‚è€ƒæ–‡æ¡£:\s*([^\]]+)\]'
                    document_match = re.search(document_pattern, reference_content)
                    if document_match:
                        documents_text = document_match.group(1).strip()
                        if documents_text and documents_text != "æ— ":
                            document_refs = [d.strip() for d in documents_text.split(',') if d.strip()]
                            logger.info(f"ğŸ“„ æå–åˆ°æ–‡æ¡£å¼•ç”¨: {document_refs}")
                            
                            # æ£€æŸ¥å‚è€ƒæ–‡æ¡£ä¸­æ˜¯å¦åŒ…å«æ³•è§„ï¼ˆå…¼å®¹å¤„ç†ï¼‰
                            regulation_keywords = ['åŠæ³•', 'è§„å®š', 'æ¡ä¾‹', 'æ³•å¾‹', 'æ³•è§„', 'æš‚è¡Œè§„å®š', 'ç®¡ç†è§„å®š']
                            potential_regulations = []
                            technical_documents = []
                            
                            for doc_ref in document_refs:
                                if any(keyword in doc_ref for keyword in regulation_keywords):
                                    potential_regulations.append(doc_ref)
                                    logger.info(f"ğŸ›ï¸ åœ¨å‚è€ƒæ–‡æ¡£ä¸­å‘ç°æ³•è§„: {doc_ref}")
                                else:
                                    technical_documents.append(doc_ref)
                            
                            # æ£€ç´¢æ³•è§„URL
                            if potential_regulations:
                                regulations = standards_service.find_regulation_by_content_keywords(' '.join(potential_regulations))
                                related_regulations.extend(regulations)
                            
                            # æ£€ç´¢æŠ€æœ¯æ–‡æ¡£URLï¼ˆä½œä¸ºå›¾çº¸æ£€ç´¢ï¼‰
                            if technical_documents and drawing_service:
                                drawings = drawing_service.get_drawings_list(limit=50)
                                for doc_ref in technical_documents:
                                    for drawing_info in drawings:
                                        drawing_db_name = drawing_info.get('drawing_name', '')
                                        original_filename = drawing_info.get('original_filename', '')
                                        
                                        # ç²¾ç¡®åŒ¹é…æˆ–åŒ…å«åŒ¹é…
                                        if (doc_ref in drawing_db_name or 
                                            drawing_db_name in doc_ref or
                                            doc_ref in original_filename):
                                            related_drawings.append(drawing_info)
                                            logger.info(f"âœ… åŒ¹é…åˆ°å‚è€ƒæ–‡æ¡£: {drawing_db_name}")
                                            break
                
                else:
                    # å…¼å®¹æ—§æ ¼å¼
                    logger.info("ğŸ“š æœªæ‰¾åˆ°æ–°æ ¼å¼å‚è€ƒä¾æ®ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼...")
                    standard_refs = standards_service.extract_standard_references(answer_text)
                    if standard_refs:
                        logger.info(f"ğŸ“Š åœ¨ç­”æ¡ˆä¸­å‘ç°æ ‡å‡†å¼•ç”¨: {standard_refs}")
                        for ref in standard_refs:
                            standards = standards_service.search_standards_by_name(ref, 2)
                            related_standards.extend(standards)
                
                # å»é‡
                related_drawings = list({d.get('drawing_name', ''): d for d in related_drawings}.values())
                
                # è®°å½•æ‰¾åˆ°çš„èµ„æº
                if related_standards:
                    logger.info(f"âœ… æ‰¾åˆ° {len(related_standards)} ä¸ªç›¸å…³æ ‡å‡†")
                if related_regulations:
                    logger.info(f"âœ… æ‰¾åˆ° {len(related_regulations)} ä¸ªç›¸å…³æ³•è§„")
                if related_drawings:
                    logger.info(f"âœ… æ‰¾åˆ° {len(related_drawings)} ä¸ªç›¸å…³å›¾çº¸")
                    
            except Exception as e:
                logger.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
        
        # æ­¥éª¤5: å°†URLæ·»åŠ åˆ°ç­”æ¡ˆä¸­
        url_info = ""
        
        # æ·»åŠ æ ‡å‡†URL
        if related_standards:
            url_info += "\n\n## ğŸ“‹ ç›¸å…³å›½å®¶æ ‡å‡†\n"
            for standard in related_standards[:3]:  # æœ€å¤š3ä¸ª
                url_info += f"â€¢ **{standard.standard_number}**: {standard.standard_name}\n"
                if standard.file_url:
                    url_info += f"  ğŸ“„ [æŸ¥çœ‹æ ‡å‡†æ–‡æ¡£]({standard.file_url})\n"
                url_info += "\n"
        
        # æ·»åŠ æ³•è§„URL
        if related_regulations:
            url_info += "\n## ğŸ›ï¸ ç›¸å…³æ³•è§„\n"
            for regulation in related_regulations[:2]:  # æœ€å¤š2ä¸ª
                url_info += f"â€¢ **{regulation.legal_name}**\n"
                if regulation.legal_url:
                    url_info += f"  ğŸ“„ [æŸ¥çœ‹æ³•è§„æ–‡æ¡£]({regulation.legal_url})\n"
                url_info += "\n"
        
        # æ·»åŠ å›¾çº¸URL
        if related_drawings:
            url_info += "\n## ğŸ“ ç›¸å…³å›¾çº¸\n"
            for drawing in related_drawings[:3]:  # æœ€å¤š3ä¸ª
                drawing_name = drawing.get('drawing_name', 'æœªçŸ¥å›¾çº¸')
                url_info += f"â€¢ **{drawing_name}**\n"
                if drawing.get('minio_url'):
                    url_info += f"  ğŸ“„ [æŸ¥çœ‹å›¾çº¸]({drawing.get('minio_url')})\n"
                url_info += "\n"
        
        # ä¼˜åŒ–å‚è€ƒä¾æ®æ˜¾ç¤ºï¼ˆéšè—"æ— "çš„ç±»åˆ«ï¼‰
        response.answer = optimize_reference_display(response.answer)
        
        # å°†URLä¿¡æ¯æ·»åŠ åˆ°ç­”æ¡ˆä¸­
        if url_info:
            response.answer += url_info
        
        # æ›´æ–°ä¼šè¯å†å²
        history.append({"role": "user", "content": request.question})
        history.append({"role": "assistant", "content": response.answer})
        session_history[session_id] = history[-10:]  # åªä¿ç•™æœ€è¿‘10è½®å¯¹è¯
        
        response.session_id = session_id
        
        logger.info(f"ç”Ÿæˆç­”æ¡ˆå®Œæˆï¼Œå¯ä¿¡åº¦: {response.confidence_score:.2f}")
        return response
        
    except Exception as e:
        logger.error(f"å¤„ç†é—®é¢˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    title: str = Form(...),
    document_type: str = Form("regulation")
):
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not any(file.filename.endswith(ext) for ext in config.SUPPORTED_FILE_TYPES):
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„ç±»å‹: {config.SUPPORTED_FILE_TYPES}"
            )
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        content_str = content.decode('utf-8', errors='ignore')
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        document = KnowledgeDocument(
            id=str(uuid.uuid4()),
            title=title,
            content=content_str,
            file_path=file.filename,
            file_type=file.filename.split('.')[-1],
            document_type=document_type,
            upload_time=datetime.now(),
            last_updated=datetime.now()
        )
        
        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        success = kb_manager.add_document(document)
        
        if success:
            return {"message": "æ–‡æ¡£ä¸Šä¼ æˆåŠŸ", "document_id": document.id}
        else:
            raise HTTPException(status_code=500, detail="æ–‡æ¡£ä¸Šä¼ å¤±è´¥")
            
    except Exception as e:
        logger.error(f"æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload-batch")
async def upload_documents_batch(
    files: List[UploadFile] = File(...),
    chunk_size: int = Form(800),
    chunk_overlap: int = Form(100)
):
    """æ‰¹é‡ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼ˆå¢é‡æ·»åŠ ï¼‰"""
    try:
        if len(files) > 20:  # é™åˆ¶å•æ¬¡ä¸Šä¼ æ–‡ä»¶æ•°é‡
            raise HTTPException(status_code=400, detail="å•æ¬¡æœ€å¤šä¸Šä¼ 20ä¸ªæ–‡ä»¶")
        
        results = []
        total_chunks = 0
        
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if not any(file.filename.endswith(ext) for ext in config.SUPPORTED_FILE_TYPES):
                results.append({
                    "filename": file.filename,
                    "status": "failed",
                    "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
                })
                continue
            
            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                content_str = content.decode('utf-8', errors='ignore')
                
                # åˆ†å‰²æ–‡æ¡£
                chunks = kb_manager.split_document(content_str, chunk_size, chunk_overlap)
                
                # å‡†å¤‡å…ƒæ•°æ®
                metadatas = []
                for i, chunk in enumerate(chunks):
                    metadata = {
                        "source_file": file.filename,
                        "chunk_index": i,
                        "chunk_count": len(chunks),
                        "document_type": "uploaded",
                        "upload_time": datetime.now().isoformat()
                    }
                    metadatas.append(metadata)
                
                # æ‰¹é‡æ·»åŠ åˆ°çŸ¥è¯†åº“
                doc_ids = kb_manager.add_documents_batch(chunks, metadatas)
                
                results.append({
                    "filename": file.filename,
                    "status": "success",
                    "chunks_added": len(doc_ids),
                    "document_ids": doc_ids[:5]  # åªè¿”å›å‰5ä¸ªID
                })
                
                total_chunks += len(chunks)
                
            except Exception as e:
                results.append({
                    "filename": file.filename,
                    "status": "failed",
                    "error": str(e)
                })
        
        # è·å–æ›´æ–°åçš„çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æ‰¹é‡ä¸Šä¼ å®Œæˆï¼Œå…±æ·»åŠ  {total_chunks} ä¸ªæ–‡æ¡£å—",
            "total_chunks_added": total_chunks,
            "files_processed": len(files),
            "results": results,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/add-text")
async def add_text_to_knowledge_base(
    request: dict
):
    """ç›´æ¥æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“ï¼ˆå¢é‡æ·»åŠ ï¼‰"""
    try:
        text_content = request.get("content", "").strip()
        title = request.get("title", "æ‰‹åŠ¨æ·»åŠ çš„æ–‡æœ¬")
        document_type = request.get("document_type", "manual")
        chunk_size = request.get("chunk_size", 800)
        chunk_overlap = request.get("chunk_overlap", 100)
        
        if not text_content:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        if len(text_content) > 50000:  # é™åˆ¶å•æ¬¡æ·»åŠ çš„æ–‡æœ¬é•¿åº¦
            raise HTTPException(status_code=400, detail="å•æ¬¡æ·»åŠ çš„æ–‡æœ¬é•¿åº¦ä¸èƒ½è¶…è¿‡50000å­—ç¬¦")
        
        # åˆ†å‰²æ–‡æ¡£
        chunks = kb_manager.split_document(text_content, chunk_size, chunk_overlap)
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadatas = []
        for i, chunk in enumerate(chunks):
            metadata = {
                "source_file": title,
                "chunk_index": i,
                "chunk_count": len(chunks),
                "document_type": document_type,
                "add_time": datetime.now().isoformat(),
                "content_length": len(chunk)
            }
            metadatas.append(metadata)
        
        # æ‰¹é‡æ·»åŠ åˆ°çŸ¥è¯†åº“
        doc_ids = kb_manager.add_documents_batch(chunks, metadatas)
        
        # è·å–æ›´æ–°åçš„çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æˆåŠŸæ·»åŠ æ–‡æœ¬ï¼Œå…±åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æ¡£å—",
            "title": title,
            "chunks_added": len(chunks),
            "document_ids": doc_ids,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/remove-documents")
async def remove_documents_by_source(
    source_file: str
):
    """æ ¹æ®æ¥æºæ–‡ä»¶åˆ é™¤æ–‡æ¡£ï¼ˆç”¨äºæ›´æ–°æ–‡æ¡£ï¼‰"""
    try:
        # è¿™ä¸ªåŠŸèƒ½éœ€è¦åœ¨BigModelKnowledgeBaseä¸­å®ç°
        # ç›®å‰ChromaDBæ”¯æŒæ ¹æ®metadataè¿‡æ»¤åˆ é™¤
        removed_count = kb_manager.remove_documents_by_source(source_file)
        
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æˆåŠŸåˆ é™¤æ¥æºä¸º '{source_file}' çš„æ–‡æ¡£",
            "removed_count": removed_count,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status", response_model=SystemStatus)
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        stats = kb_manager.get_knowledge_base_stats()
        
        return SystemStatus(
            status="æ­£å¸¸è¿è¡Œ",
            knowledge_base_stats=stats,
            llm_service_status="æ­£å¸¸",
            uptime="è¿è¡Œä¸­"
        )
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/search")
async def search_knowledge_base(query: str, top_k: int = 5):
    """æœç´¢å½“å‰çŸ¥è¯†åº“"""
    try:
        sources_result = kb_manager.search(query, n_results=top_k)
        
        results = []
        if sources_result and "results" in sources_result:
            for result in sources_result["results"]:
                results.append({
                    "content": result['content'][:200] + "..." if len(result['content']) > 200 else result['content'],
                    "file_name": result.get('metadata', {}).get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                    "standard_number": result.get('metadata', {}).get('standard_number', ''),
                    "document_type": result.get('metadata', {}).get('document_type', ''),
                    "similarity_score": result.get('similarity', 0)
                })
        
        return {
            "query": query,
            "collection": DEFAULT_COLLECTION,
            "collection_name": KNOWLEDGE_BASES[DEFAULT_COLLECTION],
            "results": results
        }
        
    except Exception as e:
        logger.error(f"çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/knowledge-bases")
async def get_knowledge_bases():
    """è·å–å¯ç”¨çš„çŸ¥è¯†åº“åˆ—è¡¨"""
    try:
        # æ£€æŸ¥æ¯ä¸ªçŸ¥è¯†åº“çš„çŠ¶æ€
        kb_status = {}
        for kb_id, kb_name in KNOWLEDGE_BASES.items():
            try:
                # ä¸´æ—¶åˆ›å»ºçŸ¥è¯†åº“ç®¡ç†å™¨æ£€æŸ¥çŠ¶æ€
                temp_kb = KnowledgeBaseManager(
                    api_key=config.bigmodel_api_key,
                    collection_name=kb_id
                )
                info = temp_kb.get_collection_info()
                kb_status[kb_id] = {
                    "name": kb_name,
                    "status": "available",
                    "document_count": info.get('count', 0),
                    "is_current": kb_id == DEFAULT_COLLECTION
                }
            except Exception as e:
                kb_status[kb_id] = {
                    "name": kb_name,
                    "status": "not_available",
                    "document_count": 0,
                    "is_current": kb_id == DEFAULT_COLLECTION,
                    "error": str(e)
                }
        
        return {
            "current_collection": DEFAULT_COLLECTION,
            "knowledge_bases": kb_status
        }
        
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/switch-knowledge-base")
async def switch_knowledge_base(request: dict):
    """åˆ‡æ¢çŸ¥è¯†åº“"""
    global kb_manager, DEFAULT_COLLECTION
    
    # å¤„ç†è¯·æ±‚å‚æ•°
    if isinstance(request, str):
        collection_name = request
    else:
        collection_name = request.get("collection_name") or request
    
    if collection_name not in KNOWLEDGE_BASES:
        raise HTTPException(
            status_code=400, 
            detail=f"æœªçŸ¥çš„çŸ¥è¯†åº“: {collection_name}. å¯ç”¨çš„çŸ¥è¯†åº“: {list(KNOWLEDGE_BASES.keys())}"
        )
    
    try:
        # åˆ›å»ºæ–°çš„çŸ¥è¯†åº“ç®¡ç†å™¨
        new_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name=collection_name
        )
        
        # æµ‹è¯•æ–°çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
        info = new_kb_manager.get_collection_info()
        
        # åˆ‡æ¢æˆåŠŸ
        kb_manager = new_kb_manager
        DEFAULT_COLLECTION = collection_name
        
        logger.info(f"æˆåŠŸåˆ‡æ¢åˆ°çŸ¥è¯†åº“: {collection_name} ({KNOWLEDGE_BASES[collection_name]})")
        
        return {
            "message": f"å·²åˆ‡æ¢åˆ° {KNOWLEDGE_BASES[collection_name]}",
            "collection": collection_name,
            "document_count": info.get('count', 0),
            "embedding_model": info.get('embedding_model', ''),
            "embedding_dimension": info.get('embedding_dimension', 0)
        }
        
    except Exception as e:
        logger.error(f"åˆ‡æ¢çŸ¥è¯†åº“å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ‡æ¢çŸ¥è¯†åº“å¤±è´¥: {str(e)}")

@app.post("/upload-drawing")
async def upload_project_drawing(
    file: UploadFile = File(...),
    project_name: str = Form(None),
    drawing_type: str = Form(None),
    drawing_phase: str = Form(None),
    created_by: str = Form(None),
    force_upload: bool = Form(False)
):
    """
    ä¸Šä¼ é¡¹ç›®å›¾çº¸PDFæ–‡æ¡£
    æ”¯æŒï¼šé‡å¤æ£€æµ‹ã€ä¸Šä¼ åˆ°MinIOã€è®°å½•åˆ°MySQLã€Geminiæ–‡æœ¬æå–ã€å‘é‡åŒ–å­˜å‚¨
    """
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ ¼å¼çš„å›¾çº¸æ–‡ä»¶")
    
    # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º100MBï¼‰
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    file_content = await file.read()
    if len(file_content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤ªå¤§ï¼Œæœ€å¤§æ”¯æŒ100MB")
    
    try:
        logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç†å›¾çº¸ä¸Šä¼ : {file.filename}")
        
        # å¤„ç†å›¾çº¸ä¸Šä¼ 
        result = drawing_service.process_drawing_upload(
            file_bytes=file_content,
            original_filename=file.filename,
            project_name=project_name,
            drawing_type=drawing_type,
            drawing_phase=drawing_phase,
            created_by=created_by,
            force_upload=force_upload
        )
        
        if result.get("success"):
            return {
                "message": "å›¾çº¸ä¸Šä¼ å’Œå¤„ç†æˆåŠŸ",
                "drawing_id": result["drawing_id"],
                "drawing_name": result["drawing_name"],
                "original_filename": result["original_filename"],
                "minio_url": result["minio_url"],
                "vector_chunks_count": result["vector_chunks_count"],
                "process_status": result["process_status"],
                "vector_status": result["vector_status"],
                "file_size_mb": round(len(file_content) / 1024 / 1024, 2),
                "knowledge_base": "drawings"
            }
        elif result.get("is_duplicate"):
            # è¿”å›é‡å¤æ–‡ä»¶ä¿¡æ¯ï¼Œè®©å‰ç«¯å¤„ç†
            return {
                "message": "æ£€æµ‹åˆ°é‡å¤æ–‡ä»¶",
                "is_duplicate": True,
                "existing_file": result["existing_file"],
                "duplicate_message": result["message"]
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"å›¾çº¸å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å›¾çº¸ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å›¾çº¸ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.get("/drawings")
async def get_drawings_list(
    project_name: str = None,
    drawing_type: str = None,
    limit: int = 50
):
    """è·å–å›¾çº¸åˆ—è¡¨"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        drawings = drawing_service.get_drawings_list(
            project_name=project_name,
            drawing_type=drawing_type,
            limit=limit
        )
        
        return {
            "message": "è·å–å›¾çº¸åˆ—è¡¨æˆåŠŸ",
            "count": len(drawings),
            "drawings": drawings,
            "filters": {
                "project_name": project_name,
                "drawing_type": drawing_type,
                "limit": limit
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾çº¸åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å›¾çº¸åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.get("/search-drawings")
async def search_project_drawings(
    query: str,
    top_k: int = 5,
    project_name: str = None,
    drawing_type: str = None
):
    """åœ¨å›¾çº¸å‘é‡æ•°æ®åº“ä¸­æœç´¢ç›¸å…³å†…å®¹"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        results = drawing_service.search_drawings_in_vector_db(
            query=query,
            top_k=top_k,
            project_name=project_name,
            drawing_type=drawing_type
        )
        
        return {
            "message": "å›¾çº¸æœç´¢å®Œæˆ",
            "query": query,
            "results_count": len(results),
            "results": results,
            "filters": {
                "project_name": project_name,
                "drawing_type": drawing_type,
                "top_k": top_k
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ å›¾çº¸æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å›¾çº¸æœç´¢å¤±è´¥: {str(e)}")

@app.get("/drawings-stats")
async def get_drawings_statistics():
    """è·å–å›¾çº¸ç»Ÿè®¡ä¿¡æ¯"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        # è·å–å‘é‡çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = drawing_service.drawings_kb.get_knowledge_base_stats()
        
        # è·å–MySQLæ•°æ®åº“ç»Ÿè®¡
        connection = drawing_service._get_mysql_connection()
        try:
            with connection.cursor() as cursor:
                # æ€»å›¾çº¸æ•°é‡
                cursor.execute("SELECT COUNT(*) as total FROM project_drawings")
                total_count = cursor.fetchone()["total"]
                
                # æŒ‰é¡¹ç›®åˆ†ç»„ç»Ÿè®¡
                cursor.execute("""
                    SELECT project_name, COUNT(*) as count 
                    FROM project_drawings 
                    WHERE project_name IS NOT NULL 
                    GROUP BY project_name 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                project_stats = cursor.fetchall()
                
                # æŒ‰å›¾çº¸ç±»å‹åˆ†ç»„ç»Ÿè®¡
                cursor.execute("""
                    SELECT drawing_type, COUNT(*) as count 
                    FROM project_drawings 
                    WHERE drawing_type IS NOT NULL 
                    GROUP BY drawing_type 
                    ORDER BY count DESC
                """)
                type_stats = cursor.fetchall()
                
                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                cursor.execute("""
                    SELECT 
                        process_status,
                        vector_status,
                        COUNT(*) as count 
                    FROM project_drawings 
                    GROUP BY process_status, vector_status
                """)
                status_stats = cursor.fetchall()
                
        finally:
            connection.close()
        
        return {
            "message": "å›¾çº¸ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ",
            "mysql_stats": {
                "total_drawings": total_count,
                "project_distribution": project_stats,
                "type_distribution": type_stats,
                "status_distribution": status_stats
            },
            "vector_kb_stats": kb_stats,
            "knowledge_base_name": "drawings"
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾çº¸ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å›¾çº¸ç»Ÿè®¡å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=config.HOST,
        port=config.PORT,
        reload=config.DEBUG,
        log_level="info"
    ) 