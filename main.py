from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from datetime import datetime
import uuid
import logging
import os
import re
from typing import List, Optional

from core.config import Config
from core.models import QuestionRequest, AnswerResponse, KnowledgeDocument, SystemStatus  
from services.bigmodel_knowledge_base import BigModelKnowledgeBase as KnowledgeBaseManager
from services.llm_service import LLMService, enhance_engineering_question
from services.mysql_standards_service import get_mysql_standards_service
from services.drawing_upload_service import get_drawing_service

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(
    title="å·¥ç¨‹ç›‘ç†æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    description="ä¸ºç°åœºç›‘ç†å·¥ç¨‹å¸ˆæä¾›è§„èŒƒå’Œå›¾çº¸æŸ¥è¯¢æœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory="static"), name="static")

# åˆå§‹åŒ–æœåŠ¡
config = Config()

# çŸ¥è¯†åº“é…ç½® - æ”¯æŒå¤šä¸ªä¸“é—¨çš„çŸ¥è¯†åº“
KNOWLEDGE_BASES = {
    "standards": "å›½å®¶æ ‡å‡†åº“",
    "engineering_knowledge_base": "åŸæœ‰å·¥ç¨‹çŸ¥è¯†åº“", 
    "regulations": "æ³•å¾‹æ³•è§„åº“",
    "drawings": "é¡¹ç›®å›¾çº¸åº“"      # é¢„ç•™
}

# é»˜è®¤ä½¿ç”¨standardsé›†åˆï¼ˆå›½å®¶æ ‡å‡†åº“ï¼‰
DEFAULT_COLLECTION = "standards"

# ä½¿ç”¨BigModelçŸ¥è¯†åº“ï¼ŒæŒ‡å®šstandardsé›†åˆ
kb_manager = KnowledgeBaseManager(
    api_key=config.bigmodel_api_key,
    collection_name=DEFAULT_COLLECTION
)
llm_service = LLMService()

# åˆå§‹åŒ–MySQLæ ‡å‡†æœåŠ¡
try:
    standards_service = get_mysql_standards_service()
    logger.info("âœ… MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ MySQLæ ‡å‡†æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    standards_service = None

# åˆå§‹åŒ–å›¾çº¸ä¸Šä¼ æœåŠ¡
try:
    drawing_service = get_drawing_service()
    logger.info("âœ… å›¾çº¸ä¸Šä¼ æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ å›¾çº¸ä¸Šä¼ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    drawing_service = None

# å­˜å‚¨ä¼šè¯å†å²ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­åº”ä½¿ç”¨æ•°æ®åº“ï¼‰
session_history = {}

def extract_used_standards_from_answer(answer: str) -> List[str]:
    """ä»ç­”æ¡ˆä¸­æå–DeepSeekæ ‡æ³¨çš„ä½¿ç”¨æ ‡å‡†"""
    # æŸ¥æ‰¾[ä½¿ç”¨æ ‡å‡†: XXX]æ ¼å¼çš„æ ‡æ³¨
    pattern = r'\[ä½¿ç”¨æ ‡å‡†:\s*([^\]]+)\]'
    match = re.search(pattern, answer)
    
    if match:
        standards_text = match.group(1).strip()
        if standards_text.lower() == "æ— ":
            return []
        
        # åˆ†å‰²å¤šä¸ªæ ‡å‡†ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
        standards = [std.strip() for std in standards_text.split(',')]
        return [std for std in standards if std]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    
    return []

def smart_filter_standards(answer: str, standards: List) -> List:
    """æ™ºèƒ½è¿‡æ»¤æ ‡å‡†ï¼šåŸºäºç­”æ¡ˆå†…å®¹è¿‡æ»¤å‡ºçœŸæ­£ç›¸å…³çš„æ ‡å‡†"""
    if not standards:
        return []
    
    # ä¸ç›¸å…³çš„æ ‡å‡†å…³é”®è¯
    irrelevant_keywords = [
        "æ°´æ•ˆé™å®šå€¼", "æ°´æ•ˆç­‰çº§", "åä¾¿å™¨", "è¹²ä¾¿å™¨", "å°ä¾¿å™¨", 
        "ä¾¿å™¨å†²æ´—é˜€", "èŠ‚æ°´", "ç”¨æ°´é‡", "å†²æ´—åŠŸèƒ½"
    ]
    
    # ç›¸å…³çš„æ ‡å‡†å…³é”®è¯
    relevant_keywords = [
        "åº”æ€¥é¿éš¾åœºæ‰€", "åœ°éœ‡åº”æ€¥", "åº”æ€¥å•æ‰€", "é¿éš¾åœºæ‰€", 
        "åœºå€åŠé…å¥—è®¾æ–½", "21734"
    ]
    
    filtered = []
    for standard in standards:
        standard_name = standard.standard_name.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç›¸å…³å…³é”®è¯
        is_irrelevant = any(keyword in standard_name for keyword in irrelevant_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
        is_relevant = any(keyword in standard_name.lower() for keyword in relevant_keywords)
        
        # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦ç›´æ¥æåŠè¯¥æ ‡å‡†
        answer_lower = answer.lower()
        standard_mentioned = (
            standard.standard_number.lower() in answer_lower or
            standard.standard_number.replace("-", "").replace(" ", "").lower() in answer_lower.replace("-", "").replace(" ", "")
        )
        
        # å†³ç­–é€»è¾‘ï¼š
        # 1. å¦‚æœåœ¨ç­”æ¡ˆä¸­è¢«æ˜ç¡®æåŠï¼Œåˆ™åŒ…å«
        # 2. å¦‚æœåŒ…å«ç›¸å…³å…³é”®è¯ä¸”ä¸åŒ…å«ä¸ç›¸å…³å…³é”®è¯ï¼Œåˆ™åŒ…å«
        # 3. å¦‚æœåŒ…å«ä¸ç›¸å…³å…³é”®è¯ï¼Œåˆ™æ’é™¤
        if standard_mentioned or (is_relevant and not is_irrelevant):
            filtered.append(standard)
        elif is_irrelevant:
            # æ˜ç¡®æ’é™¤ä¸ç›¸å…³çš„æ ‡å‡†
            logger.info(f"è¿‡æ»¤æ‰ä¸ç›¸å…³æ ‡å‡†: {standard.standard_number} - {standard.standard_name}")
            continue
    
    # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ ‡å‡†ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€ç›¸å…³çš„ï¼‰
    if not filtered and standards:
        filtered = [standards[0]]
    
    # æœ€å¤šè¿”å›2ä¸ªæ ‡å‡†ä»¥é¿å…ä¿¡æ¯è¿‡è½½
    return filtered[:2]

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    logger.info("å·¥ç¨‹ç›‘ç†æ™ºèƒ½é—®ç­”ç³»ç»Ÿå¯åŠ¨ä¸­...")
    
    # æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“ä¿¡æ¯
    try:
        info = kb_manager.get_collection_info()
        logger.info(f"ğŸ“š å½“å‰çŸ¥è¯†åº“: {KNOWLEDGE_BASES[DEFAULT_COLLECTION]} ({DEFAULT_COLLECTION})")
        logger.info(f"ğŸ“Š æ–‡æ¡£æ•°é‡: {info.get('count', 0)} ä¸ª")
        logger.info(f"ğŸ¤– å‘é‡æ¨¡å‹: {info.get('embedding_model', 'unknown')}")
        logger.info(f"ğŸ“ å‘é‡ç»´åº¦: {info.get('embedding_dimension', 0)}")
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºMySQLæ ‡å‡†åº“çŠ¶æ€
    if standards_service:
        logger.info("âœ… MySQLæ ‡å‡†æ•°æ®åº“é›†æˆå·²å¯ç”¨")
    else:
        logger.warning("âš ï¸ MySQLæ ‡å‡†æ•°æ®åº“é›†æˆæœªå¯ç”¨")
    
    logger.info("ç³»ç»Ÿå¯åŠ¨å®Œæˆ")

@app.get("/", response_class=FileResponse)
async def get_homepage():
    """è¿”å›ä¸»é¡µ"""
    return FileResponse("static/index.html")

@app.get("/admin", response_class=FileResponse)
async def get_admin_page():
    """è¿”å›ç®¡ç†é¡µé¢"""
    return FileResponse("static/admin.html")

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """å¤„ç†ç”¨æˆ·é—®é¢˜"""
    try:
        logger.info(f"æ”¶åˆ°é—®é¢˜: {request.question}")
        
        # åˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“ç®¡ç†å™¨
        standards_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name="standards"
        )
        regulations_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name="regulations"
        )
        
        # å¢å¼ºé—®é¢˜è¡¨è¿°
        enhanced_question = enhance_engineering_question(request.question)
        
        # å¤šé‡æ£€ç´¢ç­–ç•¥ï¼šä½¿ç”¨å¤šä¸ªæŸ¥è¯¢è¯æé«˜æ£€ç´¢å‡†ç¡®æ€§
        search_queries = [enhanced_question]
        
        # é’ˆå¯¹ç‰¹å®šé—®é¢˜æ·»åŠ æ›¿ä»£æŸ¥è¯¢è¯
        original_q = request.question.lower()
        if "åº”æ€¥å•æ‰€" in original_q and "è·ç¦»" in original_q:
            search_queries.extend([
                "åº”æ€¥å•æ‰€è®¾ç½®è¦æ±‚",
                "6.1.6 åº”æ€¥å•æ‰€",
                "åº”æ€¥é¿éš¾åœºæ‰€å•æ‰€è®¾ç½®",
                "GB 21734 åº”æ€¥å•æ‰€",
                "ç¯·å®¿åŒºå•æ‰€è·ç¦»"
            ])
        elif "å•æ‰€" in original_q and ("é—´è·" in original_q or "è·ç¦»" in original_q):
            search_queries.extend([
                "åº”æ€¥å•æ‰€è®¾ç½®è¦æ±‚",
                "å•æ‰€å¸ƒå±€è¦æ±‚"
            ])
        
        # æ‰§è¡Œå¤šé‡æ£€ç´¢å¹¶åˆå¹¶ç»“æœï¼ˆåŒæ—¶æœç´¢æ‰€æœ‰çŸ¥è¯†åº“ï¼‰
        all_results = []
        seen_content = set()  # é¿å…é‡å¤å†…å®¹
        
        logger.info("ğŸ” å¼€å§‹æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“...")
        
        for query in search_queries:
            # æœç´¢å›½å®¶æ ‡å‡†åº“
            logger.info(f"ğŸ“Š æœç´¢standardsåº“: {query}")
            standards_result = standards_kb_manager.search(query, n_results=config.MAX_RETRIEVAL_RESULTS)
            
            if standards_result and "results" in standards_result:
                for result in standards_result["results"]:
                    content_hash = hash(result['content'][:100])
                    if content_hash not in seen_content:
                        seen_content.add(content_hash)
                        # æ ‡è®°æ¥æºä¸ºstandards
                        result['source_type'] = 'standards'
                        all_results.append(result)
            
            # æœç´¢æ³•è§„åº“
            logger.info(f"ğŸ›ï¸ æœç´¢regulationsåº“: {query}")
            regulations_result = regulations_kb_manager.search(query, n_results=config.MAX_RETRIEVAL_RESULTS)
            
            if regulations_result and "results" in regulations_result:
                for result in regulations_result["results"]:
                    content_hash = hash(result['content'][:100])
                    if content_hash not in seen_content:
                        seen_content.add(content_hash)
                        # æ ‡è®°æ¥æºä¸ºregulations
                        result['source_type'] = 'regulations'
                        all_results.append(result)
            
            # æœç´¢å›¾çº¸çŸ¥è¯†åº“
            if drawing_service and drawing_service.drawings_kb:
                try:
                    logger.info(f"ğŸ“‹ æœç´¢drawingsåº“: {query}")
                    drawings_result = drawing_service.drawings_kb.search(query, n_results=config.MAX_RETRIEVAL_RESULTS)
                    
                    if drawings_result and "results" in drawings_result:
                        for result in drawings_result["results"]:
                            content_hash = hash(result['content'][:100])
                            if content_hash not in seen_content:
                                seen_content.add(content_hash)
                                # æ ‡è®°æ¥æºä¸ºdrawings
                                result['source_type'] = 'drawings'
                                all_results.append(result)
                except Exception as e:
                    logger.warning(f"å›¾çº¸çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶å–å‰Nä¸ªç»“æœ
        all_results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
        final_results = all_results[:config.MAX_RETRIEVAL_RESULTS * 2]  # å…è®¸æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
        
        # åŒ…è£…ä¸ºæ ‡å‡†æ ¼å¼
        sources_result = {"results": final_results}
        
        # å¤„ç†æœç´¢ç»“æœå¹¶åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        sources = []
        if sources_result and "results" in sources_result:
            for result in sources_result["results"]:
                similarity = result.get('similarity', 0)
                if similarity >= config.SIMILARITY_THRESHOLD:
                    # åˆ›å»ºå…¼å®¹DocumentSourceæ¨¡å‹çš„å¯¹è±¡
                    from core.models import DocumentSource
                    
                    metadata = result.get('metadata', {})
                    source_obj = DocumentSource(
                        title=metadata.get('standard_number', 'æœªçŸ¥æ ‡å‡†'),
                        content=result['content'],
                        source=metadata.get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                        similarity=similarity,
                        metadata=metadata,
                        file_name=metadata.get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                        regulation_code=metadata.get('standard_number', ''),
                        section=f"å—{metadata.get('chunk_index', 0)}",
                        similarity_score=similarity
                    )
                    sources.append(source_obj)
        
        if not sources:
            logger.warning(f"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼ˆé˜ˆå€¼: {config.SIMILARITY_THRESHOLD}ï¼‰ï¼Œä½¿ç”¨æ¨¡å‹é€šç”¨çŸ¥è¯†å›ç­”")
            # å½“çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³å†…å®¹æ—¶ï¼Œè®©å¤§æ¨¡å‹åŸºäºè‡ªèº«çŸ¥è¯†ç”Ÿæˆç­”æ¡ˆ
            return llm_service.generate_answer_without_context(request.question)
        
        # è·å–ä¼šè¯å†å²
        session_id = request.session_id or "default"
        history = session_history.get(session_id, [])
        
        # ç”Ÿæˆç­”æ¡ˆ
        response = llm_service.generate_answer(
            question=request.question,
            sources=sources,
            context_history=history
        )
        
        # æ ¹æ®å¤§æ¨¡å‹ç­”æ¡ˆä¸­çš„å¼•ç”¨æŸ¥è¯¢MySQLæ•°æ®åº“è·å–URL
        related_standards = []
        related_regulations = []
        related_drawings = []
        
        if standards_service:
            try:
                logger.info("ğŸ” åˆ†æå¤§æ¨¡å‹ç­”æ¡ˆä¸­çš„å¼•ç”¨...")
                
                # ä»ç­”æ¡ˆä¸­æå–æ ‡å‡†å¼•ç”¨
                answer_text = response.answer
                standard_refs = standards_service.extract_standard_references(answer_text)
                
                if standard_refs:
                    logger.info(f"ğŸ“Š åœ¨ç­”æ¡ˆä¸­å‘ç°æ ‡å‡†å¼•ç”¨: {standard_refs}")
                    for ref in standard_refs:
                        standards = standards_service.search_standards_by_name(ref, 2)
                        related_standards.extend(standards)
                
                # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦åŒ…å«æ³•è§„ç›¸å…³å†…å®¹
                regulation_keywords = [
                    'ç®¡ç†åŠæ³•', 'æ¡ä¾‹', 'æš‚è¡ŒåŠæ³•', 'ä½å®…ä¸“é¡¹ç»´ä¿®èµ„é‡‘',
                    'å”®æˆ¿å•ä½', 'å”®æˆ¿æ¬¾', 'ç¬¬å…«æ¡', 'è¡Œæ”¿å¤„ç½š',
                    'æ³•å¾‹è´£ä»»', 'è¡Œæ”¿ç®¡ç†', 'ç›‘ç£ç®¡ç†', 'èµ„é‡‘ç®¡ç†',
                    'è¿æ³•è¡Œä¸º', 'å¤„ç½šæ ‡å‡†', 'æ³•å®šèŒè´£'
                ]
                
                # æ’é™¤æŠ€æœ¯æ ‡å‡†ä¸­çš„å¸¸è§è¯æ±‡
                technical_excludes = [
                    'æ ¹æ®.*ã€Š.*ã€‹.*è§„å®š',  # æ›´ç²¾ç¡®ï¼šæ ¹æ®ã€Šæ ‡å‡†åç§°ã€‹çš„è§„å®š
                    'æ ¹æ®.*æ ‡å‡†.*è§„å®š', 'æ ¹æ®.*è§„èŒƒ.*è§„å®š', 
                    'æŠ€æœ¯è§„å®š', 'è´¨é‡è§„å®š', 'æ–½å·¥è§„å®š', 'è®¾è®¡è§„å®š', 
                    'æ£€éªŒè§„å®š', 'æ€§èƒ½è§„å®š', 'ç»„åˆ†è§„å®š', 'æºé‡è§„å®š', 
                    'å¼ºåº¦è§„å®š', 'GB.*è§„å®š', 'JGJ.*è§„å®š', 'CJJ.*è§„å®š'
                ]
                
                has_regulation_content = False
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„æ³•è§„å…³é”®è¯
                if any(keyword in answer_text for keyword in regulation_keywords):
                    # è¿›ä¸€æ­¥éªŒè¯ï¼šæ’é™¤æŠ€æœ¯æ ‡å‡†ç›¸å…³çš„"è§„å®š"
                    is_technical_regulation = any(
                        re.search(pattern, answer_text, re.IGNORECASE) 
                        for pattern in technical_excludes
                    )
                    
                    # åªæœ‰åœ¨ä¸æ˜¯æŠ€æœ¯æ ‡å‡†ç›¸å…³çš„"è§„å®š"æ—¶æ‰è®¤ä¸ºæ˜¯æ³•è§„å†…å®¹
                    if not is_technical_regulation:
                        has_regulation_content = True
                        logger.info("ğŸ›ï¸ æ£€æµ‹åˆ°æ³•è§„ç›¸å…³å†…å®¹ï¼Œä½†å·²æ’é™¤æŠ€æœ¯æ ‡å‡†è§„å®š")
                    else:
                        logger.info("ğŸ“‹ æ£€æµ‹åˆ°æŠ€æœ¯æ ‡å‡†è§„å®šï¼Œä¸æŸ¥è¯¢æ³•è§„æ•°æ®åº“")
                
                if has_regulation_content:
                    logger.info("ğŸ›ï¸ ç­”æ¡ˆæ¶‰åŠæ³•è§„å†…å®¹ï¼ŒæŸ¥è¯¢regulationsè¡¨...")
                    question_content = request.question
                    combined_content = question_content + " " + answer_text[:500]  # ç»“åˆé—®é¢˜å’Œç­”æ¡ˆå‰500å­—ç¬¦
                    regulations = standards_service.find_regulation_by_content_keywords(combined_content)
                    related_regulations = regulations
                
                # å»é‡æ ‡å‡†
                if related_standards:
                    seen_ids = set()
                    unique_standards = []
                    for standard in related_standards:
                        if standard.id not in seen_ids:
                            seen_ids.add(standard.id)
                            unique_standards.append(standard)
                    related_standards = unique_standards[:3]
                
                # è®°å½•æ‰¾åˆ°çš„èµ„æº
                if related_standards:
                    logger.info(f"âœ… æ‰¾åˆ° {len(related_standards)} ä¸ªç›¸å…³æ ‡å‡†:")
                    for std in related_standards:
                        logger.info(f"  - {std.standard_number}: {std.standard_name}")
                        logger.info(f"    URL: {std.file_url}")
                
                if related_regulations:
                    logger.info(f"âœ… æ‰¾åˆ° {len(related_regulations)} ä¸ªç›¸å…³æ³•è§„:")
                    for reg in related_regulations:
                        logger.info(f"  - {reg.legal_name}")
                        logger.info(f"    URL: {reg.legal_url}")
                
                # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦åŒ…å«å›¾çº¸ç›¸å…³å†…å®¹å¹¶æŸ¥è¯¢å›¾çº¸URL
                drawing_keywords = [
                    'å›¾çº¸', 'å¤§æ ·', 'è¯¦å›¾', 'å¹³é¢å›¾', 'ç«‹é¢å›¾', 'å‰–é¢å›¾', 
                    'èŠ‚ç‚¹å›¾', 'æ„é€ å›¾', 'é…ç­‹å›¾', 'å¢™æŸ±', 'æ¢æ¿', 'åŸºç¡€å›¾',
                    'æ–½å·¥å›¾', 'è®¾è®¡å›¾', 'å»ºç­‘å›¾', 'ç»“æ„å›¾', 'è®¾å¤‡å›¾',
                    # æ‰©å±•å›¾çº¸ç›¸å…³å…³é”®è¯
                    'è®¾è®¡è¯´æ˜', 'æ–½å·¥è¯´æ˜', 'æŠ€æœ¯è¯´æ˜', 'å·¥ç¨‹è¯´æ˜', 'è¯´æ˜ä¹¦',
                    'æ—‹æŒ–é’»å­”', 'çŒæ³¨æ¡©', 'é’»å­”æ¡©', 'ä½å®…æ¥¼', 'åŠå…¬æ¥¼',
                    'æ¡©åŸºç¡€', 'åŸºå‘æ”¯æŠ¤', 'å›´æŠ¤ç»“æ„', 'æ³¥æµ†æŠ¤å£', 'æŠ¤ç­’'
                ]
                
                # æ£€æŸ¥ç­”æ¡ˆå†…å®¹æ˜¯å¦åŒ…å«å›¾çº¸å…³é”®è¯
                has_drawing_content = any(keyword in answer_text for keyword in drawing_keywords)
                
                # ä»ä½¿ç”¨æ ‡å‡†ä¸­è¯†åˆ«å›¾çº¸æ–‡æ¡£
                used_standards = extract_used_standards_from_answer(answer_text)
                has_drawing_from_standards = False
                drawing_standard_names = []
                
                if used_standards and "æ— " not in used_standards:
                    for standard in used_standards:
                        # æ£€æŸ¥æ ‡å‡†åç§°æ˜¯å¦ä¸ºå›¾çº¸æ–‡æ¡£
                        drawing_indicators = [
                            'è®¾è®¡è¯´æ˜', 'æ–½å·¥è¯´æ˜', 'æŠ€æœ¯è¯´æ˜', 'å·¥ç¨‹è¯´æ˜',
                            'ä½å®…æ¥¼', 'åŠå…¬æ¥¼', 'å•†ä¸šæ¥¼', 'æ•™å­¦æ¥¼',
                            'æ—‹æŒ–', 'é’»å­”', 'çŒæ³¨æ¡©', 'æ¡©åŸºç¡€',
                            '.dwg', '.pdf', '_å›¾', '_è®¾è®¡', '_æ–½å·¥'
                        ]
                        
                        if any(indicator in standard for indicator in drawing_indicators):
                            has_drawing_from_standards = True
                            drawing_standard_names.append(standard)
                            logger.info(f"ğŸ¯ ä»ä½¿ç”¨æ ‡å‡†ä¸­è¯†åˆ«åˆ°å›¾çº¸æ–‡æ¡£: {standard}")
                
                # åˆå¹¶æ£€æµ‹ç»“æœ
                has_drawing_content = has_drawing_content or has_drawing_from_standards
                
                if has_drawing_content and drawing_service:
                    logger.info("ğŸ“‹ æ£€æµ‹åˆ°å›¾çº¸ç›¸å…³å†…å®¹ï¼ŒæŸ¥è¯¢å›¾çº¸æ•°æ®åº“...")
                    try:
                        # ä»ç­”æ¡ˆä¸­æå–å¯èƒ½çš„å›¾çº¸åç§°
                        drawing_names = []
                        
                        # ä¼˜å…ˆä½¿ç”¨ä»ä½¿ç”¨æ ‡å‡†ä¸­è¯†åˆ«åˆ°çš„å›¾çº¸åç§°
                        if drawing_standard_names:
                            drawing_names.extend(drawing_standard_names)
                            logger.info(f"ğŸ¯ ä¼˜å…ˆä½¿ç”¨æ ‡å‡†ä¸­çš„å›¾çº¸åç§°: {drawing_standard_names}")
                        
                        # æŸ¥æ‰¾æ‹¬å·ä¸­çš„å›¾çº¸åç§°
                        import re
                        bracket_matches = re.findall(r'[ï¼ˆ(]([^ï¼‰)]*å›¾[^ï¼‰)]*)[ï¼‰)]', answer_text)
                        drawing_names.extend(bracket_matches)
                        
                        # æŸ¥æ‰¾ç›´æ¥æåˆ°çš„å›¾çº¸åç§°
                        for keyword in drawing_keywords:
                            if keyword in answer_text:
                                # æå–åŒ…å«å…³é”®è¯çš„çŸ­è¯­
                                pattern = rf'[\w\d_\-\.]*{keyword}[\w\d_\-\.]*'
                                matches = re.findall(pattern, answer_text)
                                drawing_names.extend(matches)
                        
                        # å»é‡å¹¶æŸ¥è¯¢æ•°æ®åº“
                        unique_drawing_names = list(set(drawing_names))
                        logger.info(f"ğŸ” æå–åˆ°çš„å›¾çº¸åç§°: {unique_drawing_names}")
                        
                        for drawing_name in unique_drawing_names:
                            if len(drawing_name) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                                drawings = drawing_service.get_drawings_list(limit=50)
                                for drawing_info in drawings:
                                    drawing_db_name = drawing_info.get('drawing_name', '')
                                    original_filename = drawing_info.get('original_filename', '')
                                    
                                    # æ”¹è¿›åŒ¹é…é€»è¾‘ï¼šæ”¯æŒéƒ¨åˆ†åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
                                    if (drawing_name in drawing_db_name or 
                                        drawing_name in original_filename or
                                        drawing_db_name in drawing_name or
                                        original_filename in drawing_name):
                                        related_drawings.append(drawing_info)
                                        logger.info(f"âœ… åŒ¹é…åˆ°å›¾çº¸: {drawing_db_name} <- {drawing_name}")
                                        break
                                    
                                    # è¿›ä¸€æ­¥çš„æ¨¡ç³ŠåŒ¹é…ï¼šå¤„ç†å…³é”®è¯åŒ¹é…
                                    name_keywords = drawing_name.replace('_', ' ').split()
                                    if len(name_keywords) >= 2:
                                        matched_keywords = 0
                                        for keyword in name_keywords:
                                            if (keyword in drawing_db_name or 
                                                keyword in original_filename) and len(keyword) > 2:
                                                matched_keywords += 1
                                        
                                        # å¦‚æœåŒ¹é…åˆ°ä¸€åŠä»¥ä¸Šçš„å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯ç›¸å…³å›¾çº¸
                                        if matched_keywords >= len(name_keywords) // 2:
                                            related_drawings.append(drawing_info)
                                            logger.info(f"âœ… å…³é”®è¯åŒ¹é…åˆ°å›¾çº¸: {drawing_db_name} <- {drawing_name} (åŒ¹é…{matched_keywords}/{len(name_keywords)}ä¸ªå…³é”®è¯)")
                                            break
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„å›¾çº¸ï¼Œå°è¯•é€šè¿‡é—®é¢˜å†…å®¹å’Œè¯†åˆ«åˆ°çš„å›¾çº¸åç§°æœç´¢
                        if not related_drawings:
                            question_content = request.question
                            combined_content = question_content + " " + answer_text[:300]
                            
                            # å¦‚æœæœ‰ä»æ ‡å‡†ä¸­è¯†åˆ«åˆ°çš„å›¾çº¸åç§°ï¼Œä¼˜å…ˆä½¿ç”¨å®ƒä»¬è¿›è¡Œæœç´¢
                            if drawing_standard_names:
                                for standard_name in drawing_standard_names:
                                    combined_content += " " + standard_name
                                logger.info(f"ğŸ” ä½¿ç”¨è¯†åˆ«åˆ°çš„å›¾çº¸æ ‡å‡†åç§°è¿›è¡Œå‘é‡æœç´¢: {drawing_standard_names}")
                            
                            # ä½¿ç”¨å›¾çº¸æœç´¢åŠŸèƒ½
                            search_results = drawing_service.search_drawings_in_vector_db(
                                query=combined_content, 
                                top_k=5  # å¢åŠ æœç´¢ç»“æœæ•°é‡
                            )
                            
                            if search_results:
                                for result in search_results:
                                    drawing_id = result.get('metadata', {}).get('drawing_id')
                                    if drawing_id:
                                        drawings = drawing_service.get_drawings_list(limit=50)
                                        for drawing_info in drawings:
                                            if drawing_info.get('id') == drawing_id:
                                                related_drawings.append(drawing_info)
                                                break
                        
                        # å»é‡
                        if related_drawings:
                            seen_ids = set()
                            unique_drawings = []
                            for drawing in related_drawings:
                                if drawing.get('id') not in seen_ids:
                                    seen_ids.add(drawing.get('id'))
                                    unique_drawings.append(drawing)
                            related_drawings = unique_drawings[:3]  # æœ€å¤šæ˜¾ç¤º3ä¸ªå›¾çº¸
                        
                        if related_drawings:
                            logger.info(f"âœ… æ‰¾åˆ° {len(related_drawings)} ä¸ªç›¸å…³å›¾çº¸:")
                            for drawing in related_drawings:
                                logger.info(f"  - {drawing.get('drawing_name', 'æœªçŸ¥å›¾çº¸')}")
                                logger.info(f"    URL: {drawing.get('minio_url', 'æ— URL')}")
                    
                    except Exception as e:
                        logger.error(f"æŸ¥è¯¢å›¾çº¸æ•°æ®åº“å¤±è´¥: {e}")
                    
            except Exception as e:
                logger.error(f"æŸ¥è¯¢MySQLæ•°æ®åº“å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦çœŸæ­£å›ç­”äº†é—®é¢˜ï¼ˆå†…å®¹ç›¸å…³æ€§æ£€æŸ¥ï¼‰
        # åªæœ‰åœ¨ç¡®å®æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•ç›¸å…³å†…å®¹æ—¶æ‰å›é€€
        critical_irrelevant_patterns = [
            "æ ¹æ®æä¾›çš„è§„èŒƒæ–‡æ¡£å†…å®¹ï¼Œæœªæ£€ç´¢åˆ°",
            "æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°",
            "æ–‡æ¡£ä¸­æœªåŒ…å«ç›¸å…³ä¿¡æ¯",
            "[ä½¿ç”¨æ ‡å‡†: æ— ]"
        ]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œå…¨æ— å…³çš„å›ç­”ï¼ˆæ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼‰
        is_completely_irrelevant = any(pattern in response.answer for pattern in critical_irrelevant_patterns)
        
        # å¦‚æœæ‰¾åˆ°äº†ç›¸å…³çš„æ ‡å‡†ã€æ³•è§„æˆ–å›¾çº¸ï¼Œå³ä½¿ç­”æ¡ˆä¸­æœ‰"æœªæ‰¾åˆ°"ç­‰è¯æ±‡ï¼Œä¹Ÿä¸åº”è¯¥å›é€€
        has_relevant_resources = (len(related_standards) > 0 or len(related_regulations) > 0 or len(related_drawings) > 0)
        
        if is_completely_irrelevant and not has_relevant_resources:
            logger.warning("æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ä¸é—®é¢˜ä¸å¤Ÿç›¸å…³ï¼Œå›é€€åˆ°æ¨¡å‹çŸ¥è¯†å›ç­”")
            response = llm_service.generate_answer_without_context(request.question)
            
            # ä¸ºå›é€€ç­”æ¡ˆæ·»åŠ ä¼šè¯å†å²
            history.append({"role": "user", "content": request.question})
            history.append({"role": "assistant", "content": response.answer})
            session_history[session_id] = history[-10:]
            response.session_id = session_id
            
            return response
        
        # æå–ç­”æ¡ˆä¸­å®é™…ä½¿ç”¨çš„æ ‡å‡†å¹¶è¿‡æ»¤ç›¸å…³æ ‡å‡†åˆ—è¡¨
        filtered_standards = []
        if related_standards:
            # ä»ç­”æ¡ˆä¸­æå–DeepSeekæ ‡æ³¨çš„ä½¿ç”¨æ ‡å‡†
            used_standards = extract_used_standards_from_answer(response.answer)
            
            if used_standards and "æ— " not in used_standards:
                # æ ¹æ®ç­”æ¡ˆä¸­æ ‡æ³¨çš„æ ‡å‡†è¿‡æ»¤ç›¸å…³æ ‡å‡†åˆ—è¡¨
                for standard in related_standards:
                    standard_num = standard.standard_number.replace(" ", "").replace("-", "")
                    for used_std in used_standards:
                        used_std_clean = used_std.replace(" ", "").replace("-", "")
                        if used_std_clean in standard_num or standard_num in used_std_clean:
                            filtered_standards.append(standard)
                            break
            else:
                # å¦‚æœæ²¡æœ‰æ ‡æ³¨ä½¿ç”¨æ ‡å‡†ï¼Œä½¿ç”¨æ™ºèƒ½è¿‡æ»¤
                filtered_standards = smart_filter_standards(response.answer, related_standards)
            
            # æ·»åŠ è¿‡æ»¤åçš„æ ‡å‡†ä¿¡æ¯
            if filtered_standards:
                standard_info = "\n\nğŸ“‹ **ç›¸å…³å›½å®¶æ ‡å‡†ï¼š**\n"
                for standard in filtered_standards:
                    standard_info += f"â€¢ **{standard.standard_number}**: {standard.standard_name}\n"
                    standard_info += f"  çŠ¶æ€: {standard.status}\n"
                    if standard.file_url:
                        standard_info += f"  ğŸ“„ [æŸ¥çœ‹æ ‡å‡†æ–‡æ¡£]({standard.file_url})\n"
                    standard_info += "\n"
                
                response.answer += standard_info
        
        # æ·»åŠ ç›¸å…³æ³•è§„ä¿¡æ¯
        if related_regulations:
            regulation_info = "\n\nğŸ“‹ **ç›¸å…³æ³•å¾‹æ³•è§„ï¼š**\n"
            for regulation in related_regulations:
                regulation_info += f"â€¢ **{regulation.legal_name}**\n"
                if regulation.legal_url:
                    regulation_info += f"  ğŸ“„ [æŸ¥çœ‹æ³•è§„æ–‡æ¡£]({regulation.legal_url})\n"
                regulation_info += "\n"
            
            response.answer += regulation_info
        
        # æ·»åŠ ç›¸å…³å›¾çº¸ä¿¡æ¯
        if related_drawings:
            drawing_info = "\n\nğŸ“‹ **ç›¸å…³å·¥ç¨‹å›¾çº¸ï¼š**\n"
            for drawing in related_drawings:
                drawing_name = drawing.get('drawing_name') or drawing.get('original_filename', 'æœªçŸ¥å›¾çº¸')
                drawing_info += f"â€¢ **{drawing_name}**\n"
                
                # æ·»åŠ é¡¹ç›®ä¿¡æ¯
                if drawing.get('project_name'):
                    drawing_info += f"  é¡¹ç›®: {drawing.get('project_name')}\n"
                
                # æ·»åŠ å›¾çº¸ç±»å‹
                if drawing.get('drawing_type'):
                    drawing_info += f"  ç±»å‹: {drawing.get('drawing_type')}\n"
                
                # æ·»åŠ å›¾çº¸URL
                if drawing.get('minio_url'):
                    drawing_info += f"  ğŸ“„ [æŸ¥çœ‹å›¾çº¸æ–‡æ¡£]({drawing.get('minio_url')})\n"
                elif drawing.get('file_url'):
                    drawing_info += f"  ğŸ“„ [æŸ¥çœ‹å›¾çº¸æ–‡æ¡£]({drawing.get('file_url')})\n"
                
                drawing_info += "\n"
            
            response.answer += drawing_info
        
        # æ›´æ–°ä¼šè¯å†å²
        history.append({"role": "user", "content": request.question})
        history.append({"role": "assistant", "content": response.answer})
        session_history[session_id] = history[-10:]  # åªä¿ç•™æœ€è¿‘10è½®å¯¹è¯
        
        response.session_id = session_id
        
        logger.info(f"ç”Ÿæˆç­”æ¡ˆå®Œæˆï¼Œå¯ä¿¡åº¦: {response.confidence_score:.2f}")
        return response
        
    except Exception as e:
        logger.error(f"å¤„ç†é—®é¢˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    title: str = Form(...),
    document_type: str = Form("regulation")
):
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not any(file.filename.endswith(ext) for ext in config.SUPPORTED_FILE_TYPES):
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„ç±»å‹: {config.SUPPORTED_FILE_TYPES}"
            )
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        content_str = content.decode('utf-8', errors='ignore')
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        document = KnowledgeDocument(
            id=str(uuid.uuid4()),
            title=title,
            content=content_str,
            file_path=file.filename,
            file_type=file.filename.split('.')[-1],
            document_type=document_type,
            upload_time=datetime.now(),
            last_updated=datetime.now()
        )
        
        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        success = kb_manager.add_document(document)
        
        if success:
            return {"message": "æ–‡æ¡£ä¸Šä¼ æˆåŠŸ", "document_id": document.id}
        else:
            raise HTTPException(status_code=500, detail="æ–‡æ¡£ä¸Šä¼ å¤±è´¥")
            
    except Exception as e:
        logger.error(f"æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload-batch")
async def upload_documents_batch(
    files: List[UploadFile] = File(...),
    chunk_size: int = Form(800),
    chunk_overlap: int = Form(100)
):
    """æ‰¹é‡ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼ˆå¢é‡æ·»åŠ ï¼‰"""
    try:
        if len(files) > 20:  # é™åˆ¶å•æ¬¡ä¸Šä¼ æ–‡ä»¶æ•°é‡
            raise HTTPException(status_code=400, detail="å•æ¬¡æœ€å¤šä¸Šä¼ 20ä¸ªæ–‡ä»¶")
        
        results = []
        total_chunks = 0
        
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if not any(file.filename.endswith(ext) for ext in config.SUPPORTED_FILE_TYPES):
                results.append({
                    "filename": file.filename,
                    "status": "failed",
                    "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
                })
                continue
            
            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                content_str = content.decode('utf-8', errors='ignore')
                
                # åˆ†å‰²æ–‡æ¡£
                chunks = kb_manager.split_document(content_str, chunk_size, chunk_overlap)
                
                # å‡†å¤‡å…ƒæ•°æ®
                metadatas = []
                for i, chunk in enumerate(chunks):
                    metadata = {
                        "source_file": file.filename,
                        "chunk_index": i,
                        "chunk_count": len(chunks),
                        "document_type": "uploaded",
                        "upload_time": datetime.now().isoformat()
                    }
                    metadatas.append(metadata)
                
                # æ‰¹é‡æ·»åŠ åˆ°çŸ¥è¯†åº“
                doc_ids = kb_manager.add_documents_batch(chunks, metadatas)
                
                results.append({
                    "filename": file.filename,
                    "status": "success",
                    "chunks_added": len(doc_ids),
                    "document_ids": doc_ids[:5]  # åªè¿”å›å‰5ä¸ªID
                })
                
                total_chunks += len(chunks)
                
            except Exception as e:
                results.append({
                    "filename": file.filename,
                    "status": "failed",
                    "error": str(e)
                })
        
        # è·å–æ›´æ–°åçš„çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æ‰¹é‡ä¸Šä¼ å®Œæˆï¼Œå…±æ·»åŠ  {total_chunks} ä¸ªæ–‡æ¡£å—",
            "total_chunks_added": total_chunks,
            "files_processed": len(files),
            "results": results,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/add-text")
async def add_text_to_knowledge_base(
    request: dict
):
    """ç›´æ¥æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“ï¼ˆå¢é‡æ·»åŠ ï¼‰"""
    try:
        text_content = request.get("content", "").strip()
        title = request.get("title", "æ‰‹åŠ¨æ·»åŠ çš„æ–‡æœ¬")
        document_type = request.get("document_type", "manual")
        chunk_size = request.get("chunk_size", 800)
        chunk_overlap = request.get("chunk_overlap", 100)
        
        if not text_content:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        if len(text_content) > 50000:  # é™åˆ¶å•æ¬¡æ·»åŠ çš„æ–‡æœ¬é•¿åº¦
            raise HTTPException(status_code=400, detail="å•æ¬¡æ·»åŠ çš„æ–‡æœ¬é•¿åº¦ä¸èƒ½è¶…è¿‡50000å­—ç¬¦")
        
        # åˆ†å‰²æ–‡æ¡£
        chunks = kb_manager.split_document(text_content, chunk_size, chunk_overlap)
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadatas = []
        for i, chunk in enumerate(chunks):
            metadata = {
                "source_file": title,
                "chunk_index": i,
                "chunk_count": len(chunks),
                "document_type": document_type,
                "add_time": datetime.now().isoformat(),
                "content_length": len(chunk)
            }
            metadatas.append(metadata)
        
        # æ‰¹é‡æ·»åŠ åˆ°çŸ¥è¯†åº“
        doc_ids = kb_manager.add_documents_batch(chunks, metadatas)
        
        # è·å–æ›´æ–°åçš„çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æˆåŠŸæ·»åŠ æ–‡æœ¬ï¼Œå…±åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æ¡£å—",
            "title": title,
            "chunks_added": len(chunks),
            "document_ids": doc_ids,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/remove-documents")
async def remove_documents_by_source(
    source_file: str
):
    """æ ¹æ®æ¥æºæ–‡ä»¶åˆ é™¤æ–‡æ¡£ï¼ˆç”¨äºæ›´æ–°æ–‡æ¡£ï¼‰"""
    try:
        # è¿™ä¸ªåŠŸèƒ½éœ€è¦åœ¨BigModelKnowledgeBaseä¸­å®ç°
        # ç›®å‰ChromaDBæ”¯æŒæ ¹æ®metadataè¿‡æ»¤åˆ é™¤
        removed_count = kb_manager.remove_documents_by_source(source_file)
        
        kb_stats = kb_manager.get_knowledge_base_stats()
        
        return {
            "message": f"æˆåŠŸåˆ é™¤æ¥æºä¸º '{source_file}' çš„æ–‡æ¡£",
            "removed_count": removed_count,
            "knowledge_base_stats": kb_stats
        }
        
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status", response_model=SystemStatus)
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        stats = kb_manager.get_knowledge_base_stats()
        
        return SystemStatus(
            status="æ­£å¸¸è¿è¡Œ",
            knowledge_base_stats=stats,
            llm_service_status="æ­£å¸¸",
            uptime="è¿è¡Œä¸­"
        )
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/search")
async def search_knowledge_base(query: str, top_k: int = 5):
    """æœç´¢å½“å‰çŸ¥è¯†åº“"""
    try:
        sources_result = kb_manager.search(query, n_results=top_k)
        
        results = []
        if sources_result and "results" in sources_result:
            for result in sources_result["results"]:
                results.append({
                    "content": result['content'][:200] + "..." if len(result['content']) > 200 else result['content'],
                    "file_name": result.get('metadata', {}).get('source_file', 'æœªçŸ¥æ–‡ä»¶'),
                    "standard_number": result.get('metadata', {}).get('standard_number', ''),
                    "document_type": result.get('metadata', {}).get('document_type', ''),
                    "similarity_score": result.get('similarity', 0)
                })
        
        return {
            "query": query,
            "collection": DEFAULT_COLLECTION,
            "collection_name": KNOWLEDGE_BASES[DEFAULT_COLLECTION],
            "results": results
        }
        
    except Exception as e:
        logger.error(f"çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/knowledge-bases")
async def get_knowledge_bases():
    """è·å–å¯ç”¨çš„çŸ¥è¯†åº“åˆ—è¡¨"""
    try:
        # æ£€æŸ¥æ¯ä¸ªçŸ¥è¯†åº“çš„çŠ¶æ€
        kb_status = {}
        for kb_id, kb_name in KNOWLEDGE_BASES.items():
            try:
                # ä¸´æ—¶åˆ›å»ºçŸ¥è¯†åº“ç®¡ç†å™¨æ£€æŸ¥çŠ¶æ€
                temp_kb = KnowledgeBaseManager(
                    api_key=config.bigmodel_api_key,
                    collection_name=kb_id
                )
                info = temp_kb.get_collection_info()
                kb_status[kb_id] = {
                    "name": kb_name,
                    "status": "available",
                    "document_count": info.get('count', 0),
                    "is_current": kb_id == DEFAULT_COLLECTION
                }
            except Exception as e:
                kb_status[kb_id] = {
                    "name": kb_name,
                    "status": "not_available",
                    "document_count": 0,
                    "is_current": kb_id == DEFAULT_COLLECTION,
                    "error": str(e)
                }
        
        return {
            "current_collection": DEFAULT_COLLECTION,
            "knowledge_bases": kb_status
        }
        
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/switch-knowledge-base")
async def switch_knowledge_base(request: dict):
    """åˆ‡æ¢çŸ¥è¯†åº“"""
    global kb_manager, DEFAULT_COLLECTION
    
    # å¤„ç†è¯·æ±‚å‚æ•°
    if isinstance(request, str):
        collection_name = request
    else:
        collection_name = request.get("collection_name") or request
    
    if collection_name not in KNOWLEDGE_BASES:
        raise HTTPException(
            status_code=400, 
            detail=f"æœªçŸ¥çš„çŸ¥è¯†åº“: {collection_name}. å¯ç”¨çš„çŸ¥è¯†åº“: {list(KNOWLEDGE_BASES.keys())}"
        )
    
    try:
        # åˆ›å»ºæ–°çš„çŸ¥è¯†åº“ç®¡ç†å™¨
        new_kb_manager = KnowledgeBaseManager(
            api_key=config.bigmodel_api_key,
            collection_name=collection_name
        )
        
        # æµ‹è¯•æ–°çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
        info = new_kb_manager.get_collection_info()
        
        # åˆ‡æ¢æˆåŠŸ
        kb_manager = new_kb_manager
        DEFAULT_COLLECTION = collection_name
        
        logger.info(f"æˆåŠŸåˆ‡æ¢åˆ°çŸ¥è¯†åº“: {collection_name} ({KNOWLEDGE_BASES[collection_name]})")
        
        return {
            "message": f"å·²åˆ‡æ¢åˆ° {KNOWLEDGE_BASES[collection_name]}",
            "collection": collection_name,
            "document_count": info.get('count', 0),
            "embedding_model": info.get('embedding_model', ''),
            "embedding_dimension": info.get('embedding_dimension', 0)
        }
        
    except Exception as e:
        logger.error(f"åˆ‡æ¢çŸ¥è¯†åº“å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ‡æ¢çŸ¥è¯†åº“å¤±è´¥: {str(e)}")

@app.post("/upload-drawing")
async def upload_project_drawing(
    file: UploadFile = File(...),
    project_name: str = Form(None),
    drawing_type: str = Form(None),
    drawing_phase: str = Form(None),
    created_by: str = Form(None),
    force_upload: bool = Form(False)
):
    """
    ä¸Šä¼ é¡¹ç›®å›¾çº¸PDFæ–‡æ¡£
    æ”¯æŒï¼šé‡å¤æ£€æµ‹ã€ä¸Šä¼ åˆ°MinIOã€è®°å½•åˆ°MySQLã€Geminiæ–‡æœ¬æå–ã€å‘é‡åŒ–å­˜å‚¨
    """
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ ¼å¼çš„å›¾çº¸æ–‡ä»¶")
    
    # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º100MBï¼‰
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    file_content = await file.read()
    if len(file_content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤ªå¤§ï¼Œæœ€å¤§æ”¯æŒ100MB")
    
    try:
        logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç†å›¾çº¸ä¸Šä¼ : {file.filename}")
        
        # å¤„ç†å›¾çº¸ä¸Šä¼ 
        result = drawing_service.process_drawing_upload(
            file_bytes=file_content,
            original_filename=file.filename,
            project_name=project_name,
            drawing_type=drawing_type,
            drawing_phase=drawing_phase,
            created_by=created_by,
            force_upload=force_upload
        )
        
        if result.get("success"):
            return {
                "message": "å›¾çº¸ä¸Šä¼ å’Œå¤„ç†æˆåŠŸ",
                "drawing_id": result["drawing_id"],
                "drawing_name": result["drawing_name"],
                "original_filename": result["original_filename"],
                "minio_url": result["minio_url"],
                "vector_chunks_count": result["vector_chunks_count"],
                "process_status": result["process_status"],
                "vector_status": result["vector_status"],
                "file_size_mb": round(len(file_content) / 1024 / 1024, 2),
                "knowledge_base": "drawings"
            }
        elif result.get("is_duplicate"):
            # è¿”å›é‡å¤æ–‡ä»¶ä¿¡æ¯ï¼Œè®©å‰ç«¯å¤„ç†
            return {
                "message": "æ£€æµ‹åˆ°é‡å¤æ–‡ä»¶",
                "is_duplicate": True,
                "existing_file": result["existing_file"],
                "duplicate_message": result["message"]
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"å›¾çº¸å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å›¾çº¸ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å›¾çº¸ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.get("/drawings")
async def get_drawings_list(
    project_name: str = None,
    drawing_type: str = None,
    limit: int = 50
):
    """è·å–å›¾çº¸åˆ—è¡¨"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        drawings = drawing_service.get_drawings_list(
            project_name=project_name,
            drawing_type=drawing_type,
            limit=limit
        )
        
        return {
            "message": "è·å–å›¾çº¸åˆ—è¡¨æˆåŠŸ",
            "count": len(drawings),
            "drawings": drawings,
            "filters": {
                "project_name": project_name,
                "drawing_type": drawing_type,
                "limit": limit
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾çº¸åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å›¾çº¸åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.get("/search-drawings")
async def search_project_drawings(
    query: str,
    top_k: int = 5,
    project_name: str = None,
    drawing_type: str = None
):
    """åœ¨å›¾çº¸å‘é‡æ•°æ®åº“ä¸­æœç´¢ç›¸å…³å†…å®¹"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        results = drawing_service.search_drawings_in_vector_db(
            query=query,
            top_k=top_k,
            project_name=project_name,
            drawing_type=drawing_type
        )
        
        return {
            "message": "å›¾çº¸æœç´¢å®Œæˆ",
            "query": query,
            "results_count": len(results),
            "results": results,
            "filters": {
                "project_name": project_name,
                "drawing_type": drawing_type,
                "top_k": top_k
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ å›¾çº¸æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å›¾çº¸æœç´¢å¤±è´¥: {str(e)}")

@app.get("/drawings-stats")
async def get_drawings_statistics():
    """è·å–å›¾çº¸ç»Ÿè®¡ä¿¡æ¯"""
    if not drawing_service:
        raise HTTPException(status_code=500, detail="å›¾çº¸ä¸Šä¼ æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        # è·å–å‘é‡çŸ¥è¯†åº“ç»Ÿè®¡
        kb_stats = drawing_service.drawings_kb.get_knowledge_base_stats()
        
        # è·å–MySQLæ•°æ®åº“ç»Ÿè®¡
        connection = drawing_service._get_mysql_connection()
        try:
            with connection.cursor() as cursor:
                # æ€»å›¾çº¸æ•°é‡
                cursor.execute("SELECT COUNT(*) as total FROM project_drawings")
                total_count = cursor.fetchone()["total"]
                
                # æŒ‰é¡¹ç›®åˆ†ç»„ç»Ÿè®¡
                cursor.execute("""
                    SELECT project_name, COUNT(*) as count 
                    FROM project_drawings 
                    WHERE project_name IS NOT NULL 
                    GROUP BY project_name 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                project_stats = cursor.fetchall()
                
                # æŒ‰å›¾çº¸ç±»å‹åˆ†ç»„ç»Ÿè®¡
                cursor.execute("""
                    SELECT drawing_type, COUNT(*) as count 
                    FROM project_drawings 
                    WHERE drawing_type IS NOT NULL 
                    GROUP BY drawing_type 
                    ORDER BY count DESC
                """)
                type_stats = cursor.fetchall()
                
                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                cursor.execute("""
                    SELECT 
                        process_status,
                        vector_status,
                        COUNT(*) as count 
                    FROM project_drawings 
                    GROUP BY process_status, vector_status
                """)
                status_stats = cursor.fetchall()
                
        finally:
            connection.close()
        
        return {
            "message": "å›¾çº¸ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ",
            "mysql_stats": {
                "total_drawings": total_count,
                "project_distribution": project_stats,
                "type_distribution": type_stats,
                "status_distribution": status_stats
            },
            "vector_kb_stats": kb_stats,
            "knowledge_base_name": "drawings"
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾çº¸ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å›¾çº¸ç»Ÿè®¡å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=config.HOST,
        port=config.PORT,
        reload=config.DEBUG,
        log_level="info"
    ) 