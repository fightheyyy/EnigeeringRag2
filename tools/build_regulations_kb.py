#!/usr/bin/env python3
"""
æ„å»ºæ³•å¾‹æ³•è§„çŸ¥è¯†åº“
ä¸“é—¨ç”¨äºå¤„ç†æ³•å¾‹æ³•è§„æ–‡æ¡£ï¼Œå»ºç«‹æ³•è§„åº“é›†åˆ
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.bigmodel_knowledge_base import BigModelKnowledgeBase
from core.config import Config

class RegulationsKnowledgeBuilder:
    """æ³•è§„çŸ¥è¯†åº“æ„å»ºå™¨"""
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–æ„å»ºå™¨"""
        self.config = Config()
        self.api_key = api_key or self.config.bigmodel_api_key
        self.collection_name = "regulations"  # æ³•è§„åº“é›†åˆå
        
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®BigModel APIå¯†é’¥")
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        self.kb = BigModelKnowledgeBase(self.api_key, self.collection_name)
        
        print(f"ğŸ›ï¸ æ³•è§„çŸ¥è¯†åº“æ„å»ºå™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   é›†åˆåç§°: {self.collection_name}")
        print(f"   APIå¯†é’¥: {self.api_key[:10]}...")
        
        # æ³•è§„æ–‡æ¡£çš„ç‰¹æ®Šå¤„ç†å‚æ•°
        self.regulation_chunk_size = 600  # æ³•è§„æ¡æ–‡é€šå¸¸è¾ƒçŸ­ï¼Œä½¿ç”¨è¾ƒå°çš„å—
        self.regulation_chunk_overlap = 150  # æ›´å¤šé‡å ç¡®ä¿æ¡æ–‡è¿è´¯æ€§
    
    def add_regulation_file(self, file_path: str, regulation_info: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ·»åŠ æ³•è§„æ–‡ä»¶åˆ°çŸ¥è¯†åº“
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            regulation_info: æ³•è§„ä¿¡æ¯ï¼ˆæ³•è§„åç§°ã€å‘å¸ƒæœºæ„ã€ç”Ÿæ•ˆæ—¥æœŸç­‰ï¼‰
            
        Returns:
            æ·»åŠ ç»“æœ
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # é»˜è®¤æ³•è§„ä¿¡æ¯
        if regulation_info is None:
            regulation_info = {}
        
        print(f"ğŸ“– è¯»å–æ³•è§„æ–‡ä»¶: {file_path}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            with open(file_path, 'r', encoding='gbk') as f:
                content = f.read()
        
        print(f"   æ–‡ä»¶å¤§å°: {len(content):,} å­—ç¬¦")
        
        # æ™ºèƒ½è¯†åˆ«æ³•è§„ç»“æ„
        regulation_type = self._identify_regulation_type(content, file_path.name)
        print(f"   æ³•è§„ç±»å‹: {regulation_type}")
        
        # ä½¿ç”¨é€‚åˆçš„åˆ†å‰²ç­–ç•¥
        chunks = self._smart_split_regulation(content, regulation_type)
        print(f"   æ™ºèƒ½åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ¡æ–‡å—")
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadatas = []
        for i, chunk in enumerate(chunks):
            # å°è¯•æå–æ¡æ–‡ç¼–å·
            article_number = self._extract_article_number(chunk)
            
            metadata = {
                "source_file": file_path.name,
                "file_path": str(file_path),
                "chunk_index": i,
                "chunk_count": len(chunks),
                "regulation_type": regulation_type,
                "add_time": datetime.now().isoformat(),
                "content_length": len(chunk),
                "document_type": "regulation",
                "article_number": article_number,
                "regulation_name": regulation_info.get("name", self._extract_regulation_name(content)),
                "issuing_authority": regulation_info.get("authority", ""),
                "effective_date": regulation_info.get("effective_date", ""),
                "regulation_number": regulation_info.get("number", ""),
                "category": regulation_info.get("category", "æ³•å¾‹æ³•è§„")
            }
            metadatas.append(metadata)
        
        # æ‰¹é‡æ·»åŠ 
        print(f"ğŸ”„ æ·»åŠ åˆ°æ³•è§„çŸ¥è¯†åº“...")
        doc_ids = self.kb.add_documents_batch(chunks, metadatas)
        
        result = {
            "file_path": str(file_path),
            "regulation_type": regulation_type,
            "chunks_added": len(doc_ids),
            "document_ids": doc_ids,
            "regulation_info": regulation_info,
            "success": True
        }
        
        print(f"âœ… æˆåŠŸæ·»åŠ æ³•è§„: {file_path.name}")
        print(f"   æ·»åŠ äº† {len(doc_ids)} ä¸ªæ¡æ–‡å—")
        
        return result
    
    def _identify_regulation_type(self, content: str, filename: str) -> str:
        """æ™ºèƒ½è¯†åˆ«æ³•è§„ç±»å‹"""
        content_lower = content.lower()
        filename_lower = filename.lower()
        
        # æ³•å¾‹
        if any(keyword in content_lower for keyword in ["ä¸­åäººæ°‘å…±å’Œå›½", "æ³•", "å…¨å›½äººå¤§", "äººå¤§å¸¸å§”ä¼š"]):
            if any(keyword in filename_lower for keyword in ["æ³•", "law"]):
                return "æ³•å¾‹"
        
        # è¡Œæ”¿æ³•è§„
        if any(keyword in content_lower for keyword in ["å›½åŠ¡é™¢", "æ¡ä¾‹", "è§„å®š", "åŠæ³•"]):
            if any(keyword in filename_lower for keyword in ["æ¡ä¾‹", "è§„å®š", "åŠæ³•"]):
                return "è¡Œæ”¿æ³•è§„"
        
        # éƒ¨é—¨è§„ç« 
        if any(keyword in content_lower for keyword in ["éƒ¨", "å§”", "å±€", "ç½²"]):
            return "éƒ¨é—¨è§„ç« "
        
        # åœ°æ–¹æ³•è§„
        if any(keyword in content_lower for keyword in ["çœ", "å¸‚", "å¿", "åŒº"]):
            return "åœ°æ–¹æ³•è§„"
        
        # æŠ€æœ¯è§„èŒƒ
        if any(keyword in content_lower for keyword in ["æŠ€æœ¯è§„èŒƒ", "æ ‡å‡†", "gb", "jgj", "cjj"]):
            return "æŠ€æœ¯è§„èŒƒ"
        
        return "å…¶ä»–æ³•è§„"
    
    def _smart_split_regulation(self, content: str, regulation_type: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²æ³•è§„å†…å®¹"""
        # æ ¹æ®æ³•è§„ç±»å‹è°ƒæ•´åˆ†å‰²ç­–ç•¥
        if regulation_type in ["æ³•å¾‹", "è¡Œæ”¿æ³•è§„"]:
            return self._split_by_articles(content)
        elif regulation_type == "æŠ€æœ¯è§„èŒƒ":
            return self._split_by_sections(content)
        else:
            # é»˜è®¤åˆ†å‰²
            return self.kb.split_document(content, self.regulation_chunk_size, self.regulation_chunk_overlap)
    
    def _split_by_articles(self, content: str) -> List[str]:
        """æŒ‰æ¡æ–‡åˆ†å‰²æ³•è§„"""
        import re
        
        # æŸ¥æ‰¾æ¡æ–‡æ ‡è®°
        article_pattern = r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡[ï¼š\s]'
        articles = re.split(article_pattern, content)
        
        if len(articles) > 1:
            # é‡æ–°ç»„åˆï¼Œä¿ç•™æ¡æ–‡æ ‡å·
            matches = re.findall(article_pattern, content)
            chunks = []
            
            for i, article_content in enumerate(articles[1:]):  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå…ƒç´ 
                if i < len(matches):
                    chunk = matches[i] + article_content.strip()
                    if len(chunk) > 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                        chunks.append(chunk)
            
            print(f"   æŒ‰æ¡æ–‡åˆ†å‰²: {len(chunks)} æ¡")
            return chunks
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¡æ–‡æ ‡è®°ï¼Œä½¿ç”¨é»˜è®¤åˆ†å‰²
        return self.kb.split_document(content, self.regulation_chunk_size, self.regulation_chunk_overlap)
    
    def _split_by_sections(self, content: str) -> List[str]:
        """æŒ‰ç« èŠ‚åˆ†å‰²æŠ€æœ¯è§„èŒƒ"""
        import re
        
        # æŸ¥æ‰¾ç« èŠ‚æ ‡è®°
        section_patterns = [
            r'\d+\.\d+\s+[^\r\n]+',  # å¦‚: 3.1 æ€»åˆ™
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« [ï¼š\s]',  # å¦‚: ç¬¬ä¸‰ç« 
            r'\d+\s+[^\r\n]+(?=\n)',  # å¦‚: 3 åŸºæœ¬è§„å®š
        ]
        
        for pattern in section_patterns:
            sections = re.split(pattern, content)
            if len(sections) > 2:  # è‡³å°‘è¦æœ‰3ä¸ªéƒ¨åˆ†æ‰ç®—æœ‰æ•ˆåˆ†å‰²
                matches = re.findall(pattern, content)
                chunks = []
                
                for i, section_content in enumerate(sections[1:]):
                    if i < len(matches):
                        chunk = matches[i] + section_content.strip()
                        if len(chunk) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                            chunks.append(chunk)
                
                if chunks:
                    print(f"   æŒ‰ç« èŠ‚åˆ†å‰²: {len(chunks)} èŠ‚")
                    return chunks
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚æ ‡è®°ï¼Œä½¿ç”¨é»˜è®¤åˆ†å‰²
        return self.kb.split_document(content, self.regulation_chunk_size, self.regulation_chunk_overlap)
    
    def _extract_article_number(self, content: str) -> str:
        """æå–æ¡æ–‡ç¼–å·"""
        import re
        
        # æŸ¥æ‰¾æ¡æ–‡ç¼–å·
        patterns = [
            r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+)æ¡',
            r'(\d+\.\d+(?:\.\d+)?)',  # å¦‚: 3.1.1
            r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ç« ',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content[:100])  # åªåœ¨å‰100å­—ç¬¦ä¸­æŸ¥æ‰¾
            if match:
                return match.group(1)
        
        return ""
    
    def _extract_regulation_name(self, content: str) -> str:
        """ä»å†…å®¹ä¸­æå–æ³•è§„åç§°"""
        import re
        
        # å¸¸è§çš„æ³•è§„åç§°æ¨¡å¼
        patterns = [
            r'ã€Š([^ã€‹]+)ã€‹',  # ã€Šæ³•è§„åç§°ã€‹æ ¼å¼
            r'([^ï¼ˆ\n\r]+)(?:ï¼ˆ[^ï¼‰]*ï¼‰)?(?:æ³•|æ¡ä¾‹|è§„å®š|åŠæ³•|æ ‡å‡†)',  # ä»¥æ³•ã€æ¡ä¾‹ç­‰ç»“å°¾
        ]
        
        first_lines = content[:500]  # åœ¨å‰500å­—ç¬¦ä¸­æŸ¥æ‰¾
        
        for pattern in patterns:
            matches = re.findall(pattern, first_lines)
            if matches:
                name = matches[0].strip()
                if len(name) < 100 and len(name) > 3:  # åˆç†çš„åç§°é•¿åº¦
                    return name
        
        return "æœªçŸ¥æ³•è§„"
    
    def build_from_directory(self, dir_path: str, recursive: bool = True) -> Dict[str, Any]:
        """
        ä»ç›®å½•æ„å»ºæ³•è§„åº“
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’å¤„ç†å­ç›®å½•
            
        Returns:
            æ„å»ºç»“æœ
        """
        dir_path = Path(dir_path)
        
        if not dir_path.exists() or not dir_path.is_dir():
            raise ValueError(f"ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {dir_path}")
        
        print(f"ğŸ“ æ„å»ºæ³•è§„åº“ï¼Œå¤„ç†ç›®å½•: {dir_path}")
        
        # æŸ¥æ‰¾æ³•è§„æ–‡ä»¶
        supported_types = ['.txt', '.md']
        files = []
        
        if recursive:
            for ext in supported_types:
                files.extend(dir_path.rglob(f"*{ext}"))
        else:
            for ext in supported_types:
                files.extend(dir_path.glob(f"*{ext}"))
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼Œä¼˜å…ˆå¤„ç†æ³•å¾‹æ–‡ä»¶
        def sort_key(file_path):
            name = file_path.name.lower()
            if 'æ³•' in name:
                return 0  # æ³•å¾‹ä¼˜å…ˆ
            elif 'æ¡ä¾‹' in name or 'è§„å®š' in name:
                return 1  # è¡Œæ”¿æ³•è§„æ¬¡ä¹‹
            elif 'åŠæ³•' in name:
                return 2  # éƒ¨é—¨è§„ç« 
            else:
                return 3  # å…¶ä»–
        
        files.sort(key=sort_key)
        print(f"   æ‰¾åˆ° {len(files)} ä¸ªæ³•è§„æ–‡ä»¶")
        
        if not files:
            return {"success": False, "message": "æœªæ‰¾åˆ°æ³•è§„æ–‡ä»¶"}
        
        results = []
        total_chunks = 0
        successful_files = 0
        
        for file_path in files:
            try:
                print(f"\nå¤„ç†æ³•è§„æ–‡ä»¶: {file_path.name}")
                
                # æ ¹æ®æ–‡ä»¶åæ¨æ–­æ³•è§„ä¿¡æ¯
                regulation_info = self._infer_regulation_info(file_path.name)
                
                result = self.add_regulation_file(file_path, regulation_info)
                results.append(result)
                total_chunks += result["chunks_added"]
                successful_files += 1
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path.name} - {e}")
                results.append({
                    "file_path": str(file_path),
                    "success": False,
                    "error": str(e)
                })
        
        summary = {
            "directory": str(dir_path),
            "collection_name": self.collection_name,
            "total_files": len(files),
            "successful_files": successful_files,
            "total_chunks": total_chunks,
            "results": results,
            "success": successful_files > 0
        }
        
        print(f"\nğŸ“Š æ³•è§„åº“æ„å»ºå®Œæˆ:")
        print(f"   æˆåŠŸå¤„ç†: {successful_files}/{len(files)} ä¸ªæ–‡ä»¶")
        print(f"   æ€»æ¡æ–‡å—: {total_chunks}")
        print(f"   çŸ¥è¯†åº“é›†åˆ: {self.collection_name}")
        
        return summary
    
    def _infer_regulation_info(self, filename: str) -> Dict[str, Any]:
        """æ ¹æ®æ–‡ä»¶åæ¨æ–­æ³•è§„ä¿¡æ¯"""
        info = {
            "name": "",
            "authority": "",
            "category": "æ³•å¾‹æ³•è§„",
            "number": "",
            "effective_date": ""
        }
        
        filename_lower = filename.lower()
        
        # æ¨æ–­æ³•è§„ç±»å‹å’Œå‘å¸ƒæœºæ„
        if 'å»ºç­‘æ³•' in filename or 'åŸå¸‚è§„åˆ’æ³•' in filename:
            info["authority"] = "å…¨å›½äººå¤§å¸¸å§”ä¼š"
            info["category"] = "æ³•å¾‹"
        elif 'å»ºè®¾å·¥ç¨‹' in filename and 'æ¡ä¾‹' in filename:
            info["authority"] = "å›½åŠ¡é™¢"
            info["category"] = "è¡Œæ”¿æ³•è§„"
        elif 'ä½å»ºéƒ¨' in filename or 'å»ºè®¾éƒ¨' in filename:
            info["authority"] = "ä½æˆ¿å’ŒåŸä¹¡å»ºè®¾éƒ¨"
            info["category"] = "éƒ¨é—¨è§„ç« "
        elif 'gb' in filename_lower:
            info["authority"] = "å›½å®¶æ ‡å‡†åŒ–ç®¡ç†å§”å‘˜ä¼š"
            info["category"] = "å›½å®¶æ ‡å‡†"
        
        # æå–æ³•è§„åç§°ï¼ˆå»é™¤æ–‡ä»¶æ‰©å±•åï¼‰
        name_without_ext = Path(filename).stem
        info["name"] = name_without_ext
        
        return info
    
    def get_regulations_stats(self) -> Dict[str, Any]:
        """è·å–æ³•è§„åº“ç»Ÿè®¡ä¿¡æ¯"""
        basic_stats = self.kb.get_knowledge_base_stats()
        
        # è·å–æ³•è§„åˆ†ç±»ç»Ÿè®¡
        try:
            # è¿™é‡Œå¯ä»¥æ‰©å±•ï¼ŒæŸ¥è¯¢ä¸åŒç±»å‹æ³•è§„çš„æ•°é‡
            regulations_by_type = {
                "æ³•å¾‹": 0,
                "è¡Œæ”¿æ³•è§„": 0,
                "éƒ¨é—¨è§„ç« ": 0,
                "åœ°æ–¹æ³•è§„": 0,
                "æŠ€æœ¯è§„èŒƒ": 0,
                "å…¶ä»–": 0
            }
            
            return {
                **basic_stats,
                "regulations_by_type": regulations_by_type,
                "collection_description": "æ³•å¾‹æ³•è§„ä¸“é—¨çŸ¥è¯†åº“"
            }
        except Exception:
            return basic_stats

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›ï¸ æ³•è§„çŸ¥è¯†åº“æ„å»ºå·¥å…·")
    print("=" * 50)
    
    try:
        # ä»é…ç½®æ–‡ä»¶è·å–APIå¯†é’¥
        config = Config()
        api_key = config.bigmodel_api_key
        if not api_key:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°BigModel APIå¯†é’¥ï¼Œè¯·åœ¨config.pyä¸­è®¾ç½®bigmodel_api_key")
            return
        
        print(f"ğŸ”‘ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥: {api_key[:10]}...")
        
        # åˆå§‹åŒ–æ„å»ºå™¨
        builder = RegulationsKnowledgeBuilder(api_key)
        
        # æ£€æŸ¥æ³•è§„æ–‡æ¡£ç›®å½•
        regulations_dir = Path("./regulations")
        if not regulations_dir.exists():
            print(f"ğŸ“ åˆ›å»ºæ³•è§„æ–‡æ¡£ç›®å½•: {regulations_dir}")
            regulations_dir.mkdir(exist_ok=True)
            print(f"è¯·å°†æ³•è§„æ–‡æ¡£ï¼ˆ.txt æˆ– .md æ ¼å¼ï¼‰æ”¾å…¥ {regulations_dir} ç›®å½•")
            return
        
        # æ£€æŸ¥é›†åˆçŠ¶æ€
        current_stats = builder.get_regulations_stats()
        current_count = current_stats.get("total_chunks", 0)
        
        if current_count > 0:
            print(f"ğŸ“š å½“å‰æ³•è§„åº“å·²æœ‰ {current_count} ä¸ªæ–‡æ¡£å—")
            choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®é‡æ–°æ„å»ºï¼Ÿ(y/N): ").strip().lower()
            if choice == 'y':
                builder.kb.clear_collection()
                print("ğŸ—‘ï¸ å·²æ¸…ç©ºç°æœ‰æ³•è§„æ•°æ®")
        
        # æ„å»ºæ³•è§„åº“
        print(f"\nğŸ”„ å¼€å§‹æ„å»ºæ³•è§„çŸ¥è¯†åº“...")
        result = builder.build_from_directory(regulations_dir, recursive=True)
        
        if result["success"]:
            print(f"\nğŸ‰ æ³•è§„åº“æ„å»ºæˆåŠŸï¼")
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            final_stats = builder.get_regulations_stats()
            print(f"\nğŸ“Š æ³•è§„åº“ç»Ÿè®¡:")
            print(f"   é›†åˆåç§°: {final_stats['collection_name']}")
            print(f"   æ–‡æ¡£æ€»æ•°: {final_stats['total_chunks']}")
            print(f"   å‘é‡æ¨¡å‹: {final_stats['embedding_model']}")
            print(f"   å‘é‡ç»´åº¦: {final_stats['embedding_dimension']}")
            
            # æµ‹è¯•æœç´¢åŠŸèƒ½
            print(f"\nğŸ§ª æµ‹è¯•æ³•è§„åº“æœç´¢åŠŸèƒ½...")
            test_queries = [
                "å»ºç­‘å·¥ç¨‹è´¨é‡ç®¡ç†",
                "å·¥ç¨‹ç›‘ç†èŒè´£",
                "æ–½å·¥è®¸å¯è¯",
                "å®‰å…¨ç”Ÿäº§è´£ä»»",
                "å·¥ç¨‹ç«£å·¥éªŒæ”¶"
            ]
            
            for query in test_queries:
                print(f"\nğŸ” æœç´¢æµ‹è¯•: '{query}'")
                results = builder.kb.search(query, n_results=2)
                
                if results["results"]:
                    for i, result in enumerate(results["results"]):
                        similarity = result.get('similarity', 0)
                        regulation_name = result['metadata'].get('regulation_name', 'æœªçŸ¥æ³•è§„')
                        article_number = result['metadata'].get('article_number', '')
                        
                        print(f"   ç»“æœ{i+1}: ç›¸ä¼¼åº¦={similarity:.3f}")
                        print(f"   æ³•è§„: {regulation_name}")
                        if article_number:
                            print(f"   æ¡æ–‡: ç¬¬{article_number}æ¡")
                        print(f"   å†…å®¹: {result['content'][:100]}...")
                else:
                    print("   æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            print(f"\nâœ… æ³•è§„åº“å·²å‡†å¤‡å°±ç»ªï¼Œç°åœ¨å¯ä»¥åˆ‡æ¢åˆ°æ³•è§„åº“è¿›è¡Œé—®ç­”ï¼")
            print(f"   ä½¿ç”¨å‘½ä»¤: åœ¨Webç•Œé¢ä¸­é€‰æ‹©åˆ‡æ¢åˆ°ã€Œæ³•å¾‹æ³•è§„åº“ã€")
        else:
            print(f"\nâŒ æ³•è§„åº“æ„å»ºå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    except Exception as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 